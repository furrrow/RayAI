{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Getting Started - Hyperparameter Tuning #\n",
    "Ray's quickstart on Hyperparameter tuning:\n",
    "https://docs.ray.io/en/latest/train/dl_guide.html#hyperparameter-tuning-ray-tune\n",
    "\n",
    "and also\n",
    "https://docs.ray.io/en/latest/tune/getting-started.html#tune-tutorial\n",
    "\n",
    "combined with Torch's Quickstart guide:\n",
    "https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html\n",
    "\n",
    "and their version of ray tuning guide:\n",
    "https://pytorch.org/tutorials/beginner/hyperparameter_tuning_tutorial.html"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from ray import tune\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from ray import air\n",
    "import torchmetrics\n",
    "import numpy as np\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T18:57:25.643902773Z",
     "start_time": "2023-05-14T18:57:24.410621796Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Download training data from open datasets.\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T18:57:25.678599256Z",
     "start_time": "2023-05-14T18:57:25.644706004Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class NaiveDense(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28 * 28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        inputs = self.flatten(inputs)\n",
    "        logits = self.linear_relu_stack(inputs)\n",
    "        return logits"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T18:57:25.680950849Z",
     "start_time": "2023-05-14T18:57:25.679894759Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def train_fashion(config, checkpoint_dir=None, data_dir=None):\n",
    "    num_epochs=3\n",
    "    batch_size = config['batch_size']\n",
    "    # checkpoint_dir = config['checkpoint_dir']\n",
    "    model_state_name = \"serial_model.pth\"\n",
    "    train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "    test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "    device = (\n",
    "        \"cuda\"\n",
    "        if torch.cuda.is_available()\n",
    "        else \"mps\"\n",
    "        if torch.backends.mps.is_available()\n",
    "        else \"cpu\"\n",
    "    )\n",
    "    device = \"cpu\"\n",
    "    model = NaiveDense().to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(\n",
    "        model.parameters(), lr=config[\"lr\"], momentum=config[\"momentum\"]\n",
    "    )\n",
    "\n",
    "    if checkpoint_dir:\n",
    "        model_state, optimizer_state = torch.load(\n",
    "            os.path.join(checkpoint_dir, \"checkpoint\"))\n",
    "        model.load_state_dict(model_state)\n",
    "        optimizer.load_state_dict(optimizer_state)\n",
    "\n",
    "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        epoch_steps = 0\n",
    "        for i, data in enumerate(train_dataloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            epoch_steps += 1\n",
    "            if i % 2000 == 1999:  # print every 2000 mini-batches\n",
    "                print(\"[%d, %5d] loss: %.3f\" % (epoch + 1, i + 1,\n",
    "                                                running_loss / epoch_steps))\n",
    "                running_loss = 0.0\n",
    "\n",
    "        # Validation loss\n",
    "        val_loss = 0.0\n",
    "        val_steps = 0\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        for i, data in enumerate(test_dataloader, 0):\n",
    "            with torch.no_grad():\n",
    "                inputs, labels = data\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.cpu().numpy()\n",
    "                val_steps += 1\n",
    "\n",
    "        with tune.checkpoint_dir(epoch) as checkpoint_dir:\n",
    "            path = os.path.join(checkpoint_dir, \"checkpoint\")\n",
    "            torch.save((model.state_dict(), optimizer.state_dict()), path)\n",
    "\n",
    "        tune.report(loss=(val_loss / val_steps), accuracy=correct / total)\n",
    "    print(\"Finished Training\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T18:57:25.688075408Z",
     "start_time": "2023-05-14T18:57:25.681493476Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def test_accuracy(net, device=\"cpu\"):\n",
    "    batch_size=64\n",
    "    test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_dataloader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return correct / total"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T18:57:25.691389132Z",
     "start_time": "2023-05-14T18:57:25.689766049Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Session not detected. You should not be calling `checkpoint_dir` outside `tuner.fit()` or while using the class API. \n",
      "  File \"/home/jim/mambaforge/envs/ray/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/home/jim/mambaforge/envs/ray/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/jim/mambaforge/envs/ray/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/home/jim/mambaforge/envs/ray/lib/python3.10/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n",
      "    app.start()\n",
      "  File \"/home/jim/mambaforge/envs/ray/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 725, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/home/jim/mambaforge/envs/ray/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 195, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/home/jim/mambaforge/envs/ray/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/home/jim/mambaforge/envs/ray/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"/home/jim/mambaforge/envs/ray/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/home/jim/mambaforge/envs/ray/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 513, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/home/jim/mambaforge/envs/ray/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 502, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/home/jim/mambaforge/envs/ray/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 409, in dispatch_shell\n",
      "    await result\n",
      "  File \"/home/jim/mambaforge/envs/ray/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/home/jim/mambaforge/envs/ray/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/home/jim/mambaforge/envs/ray/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/home/jim/mambaforge/envs/ray/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/home/jim/mambaforge/envs/ray/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/home/jim/mambaforge/envs/ray/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/home/jim/mambaforge/envs/ray/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/home/jim/mambaforge/envs/ray/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/home/jim/mambaforge/envs/ray/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_480831/3425001798.py\", line 5, in <module>\n",
      "    train_fashion(config)\n",
      "  File \"/tmp/ipykernel_480831/3913614184.py\", line 73, in train_fashion\n",
      "    with tune.checkpoint_dir(epoch) as checkpoint_dir:\n",
      "  File \"/home/jim/mambaforge/envs/ray/lib/python3.10/contextlib.py\", line 135, in __enter__\n",
      "    return next(self.gen)\n",
      "\n",
      "Session not detected. You should not be calling `report` outside `tuner.fit()` or while using the class API. \n",
      "  File \"/home/jim/mambaforge/envs/ray/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/home/jim/mambaforge/envs/ray/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/jim/mambaforge/envs/ray/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/home/jim/mambaforge/envs/ray/lib/python3.10/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n",
      "    app.start()\n",
      "  File \"/home/jim/mambaforge/envs/ray/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 725, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/home/jim/mambaforge/envs/ray/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 195, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/home/jim/mambaforge/envs/ray/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/home/jim/mambaforge/envs/ray/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"/home/jim/mambaforge/envs/ray/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/home/jim/mambaforge/envs/ray/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 513, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/home/jim/mambaforge/envs/ray/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 502, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/home/jim/mambaforge/envs/ray/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 409, in dispatch_shell\n",
      "    await result\n",
      "  File \"/home/jim/mambaforge/envs/ray/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/home/jim/mambaforge/envs/ray/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/home/jim/mambaforge/envs/ray/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/home/jim/mambaforge/envs/ray/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/home/jim/mambaforge/envs/ray/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/home/jim/mambaforge/envs/ray/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/home/jim/mambaforge/envs/ray/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/home/jim/mambaforge/envs/ray/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/home/jim/mambaforge/envs/ray/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_480831/3425001798.py\", line 5, in <module>\n",
      "    train_fashion(config)\n",
      "  File \"/tmp/ipykernel_480831/3913614184.py\", line 77, in train_fashion\n",
      "    tune.report(loss=(val_loss / val_steps), accuracy=correct / total)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# first make sure it runs\n",
    "config = {\"batch_size\":64,\n",
    "          \"lr\": 0.001,\n",
    "          \"momentum\": 0.8}\n",
    "train_fashion(config)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T18:57:40.149556702Z",
     "start_time": "2023-05-14T18:57:25.692756420Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-14 14:57:41,927\tINFO worker.py:1616 -- Started a local Ray instance. View the dashboard at \u001B[1m\u001B[32m127.0.0.1:8265 \u001B[39m\u001B[22m\n",
      "2023-05-14 14:57:45,311\tINFO tune.py:218 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `Tuner(...)`.\n",
      "/home/jim/mambaforge/envs/ray/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py:611: DeprecationWarning: `checkpoint_dir` in `func(config, checkpoint_dir)` is being deprecated. To save and load checkpoint in trainable functions, please use the `ray.air.session` API:\n",
      "\n",
      "from ray.air import session\n",
      "\n",
      "def train(config):\n",
      "    # ...\n",
      "    session.report({\"metric\": metric}, checkpoint=checkpoint)\n",
      "\n",
      "For more information please see https://docs.ray.io/en/latest/tune/api/trainable.html\n",
      "\n",
      "  warnings.warn(\n",
      "2023-05-14 14:57:54,439\tWARNING worker.py:1986 -- Warning: The actor ImplicitFunc is very large (52 MiB). Check that its definition is not implicitly capturing a large array or other object in scope. Tip: use ray.put() to put large objects in the Ray object store.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-05-14 14:57:54 (running for 00:00:08.20)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 4.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/jim/ray_results/train_fashion_2023-05-14_14-57-40\n",
      "Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n",
      "+---------------------------+----------+----------------------+--------------+-------------+------------+\n",
      "| Trial name                | status   | loc                  |   batch_size |          lr |   momentum |\n",
      "|---------------------------+----------+----------------------+--------------+-------------+------------|\n",
      "| train_fashion_369b0_00000 | RUNNING  | 192.168.0.135:481602 |          128 | 0.000330542 |   0.353592 |\n",
      "| train_fashion_369b0_00001 | PENDING  |                      |           64 | 0.00186854  |   0.843826 |\n",
      "| train_fashion_369b0_00002 | PENDING  |                      |          128 | 0.00029119  |   0.552573 |\n",
      "| train_fashion_369b0_00003 | PENDING  |                      |          128 | 0.00043195  |   0.47837  |\n",
      "| train_fashion_369b0_00004 | PENDING  |                      |           16 | 0.00708167  |   0.769759 |\n",
      "| train_fashion_369b0_00005 | PENDING  |                      |           16 | 0.000162291 |   0.36995  |\n",
      "| train_fashion_369b0_00006 | PENDING  |                      |           64 | 0.00289137  |   0.818959 |\n",
      "| train_fashion_369b0_00007 | PENDING  |                      |           64 | 0.00169799  |   0.684505 |\n",
      "| train_fashion_369b0_00008 | PENDING  |                      |           16 | 0.00102337  |   0.700704 |\n",
      "| train_fashion_369b0_00009 | PENDING  |                      |           16 | 0.000636541 |   0.802663 |\n",
      "+---------------------------+----------+----------------------+--------------+-------------+------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-05-14 14:58:03 (running for 00:00:17.06)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/jim/ray_results/train_fashion_2023-05-14_14-57-40\n",
      "Number of trials: 10/10 (6 PENDING, 4 RUNNING)\n",
      "+---------------------------+----------+----------------------+--------------+-------------+------------+\n",
      "| Trial name                | status   | loc                  |   batch_size |          lr |   momentum |\n",
      "|---------------------------+----------+----------------------+--------------+-------------+------------|\n",
      "| train_fashion_369b0_00000 | RUNNING  | 192.168.0.135:481602 |          128 | 0.000330542 |   0.353592 |\n",
      "| train_fashion_369b0_00001 | RUNNING  | 192.168.0.135:481650 |           64 | 0.00186854  |   0.843826 |\n",
      "| train_fashion_369b0_00002 | RUNNING  | 192.168.0.135:481652 |          128 | 0.00029119  |   0.552573 |\n",
      "| train_fashion_369b0_00003 | RUNNING  | 192.168.0.135:481684 |          128 | 0.00043195  |   0.47837  |\n",
      "| train_fashion_369b0_00004 | PENDING  |                      |           16 | 0.00708167  |   0.769759 |\n",
      "| train_fashion_369b0_00005 | PENDING  |                      |           16 | 0.000162291 |   0.36995  |\n",
      "| train_fashion_369b0_00006 | PENDING  |                      |           64 | 0.00289137  |   0.818959 |\n",
      "| train_fashion_369b0_00007 | PENDING  |                      |           64 | 0.00169799  |   0.684505 |\n",
      "| train_fashion_369b0_00008 | PENDING  |                      |           16 | 0.00102337  |   0.700704 |\n",
      "| train_fashion_369b0_00009 | PENDING  |                      |           16 | 0.000636541 |   0.802663 |\n",
      "+---------------------------+----------+----------------------+--------------+-------------+------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-05-14 14:58:09 (running for 00:00:22.65)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/jim/ray_results/train_fashion_2023-05-14_14-57-40\n",
      "Number of trials: 10/10 (6 PENDING, 4 RUNNING)\n",
      "+---------------------------+----------+----------------------+--------------+-------------+------------+\n",
      "| Trial name                | status   | loc                  |   batch_size |          lr |   momentum |\n",
      "|---------------------------+----------+----------------------+--------------+-------------+------------|\n",
      "| train_fashion_369b0_00000 | RUNNING  | 192.168.0.135:481602 |          128 | 0.000330542 |   0.353592 |\n",
      "| train_fashion_369b0_00001 | RUNNING  | 192.168.0.135:481650 |           64 | 0.00186854  |   0.843826 |\n",
      "| train_fashion_369b0_00002 | RUNNING  | 192.168.0.135:481652 |          128 | 0.00029119  |   0.552573 |\n",
      "| train_fashion_369b0_00003 | RUNNING  | 192.168.0.135:481684 |          128 | 0.00043195  |   0.47837  |\n",
      "| train_fashion_369b0_00004 | PENDING  |                      |           16 | 0.00708167  |   0.769759 |\n",
      "| train_fashion_369b0_00005 | PENDING  |                      |           16 | 0.000162291 |   0.36995  |\n",
      "| train_fashion_369b0_00006 | PENDING  |                      |           64 | 0.00289137  |   0.818959 |\n",
      "| train_fashion_369b0_00007 | PENDING  |                      |           64 | 0.00169799  |   0.684505 |\n",
      "| train_fashion_369b0_00008 | PENDING  |                      |           16 | 0.00102337  |   0.700704 |\n",
      "| train_fashion_369b0_00009 | PENDING  |                      |           16 | 0.000636541 |   0.802663 |\n",
      "+---------------------------+----------+----------------------+--------------+-------------+------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-05-14 14:58:14 (running for 00:00:27.65)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 2.000: None | Iter 1.000: None\n",
      "Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/jim/ray_results/train_fashion_2023-05-14_14-57-40\n",
      "Number of trials: 10/10 (6 PENDING, 4 RUNNING)\n",
      "+---------------------------+----------+----------------------+--------------+-------------+------------+\n",
      "| Trial name                | status   | loc                  |   batch_size |          lr |   momentum |\n",
      "|---------------------------+----------+----------------------+--------------+-------------+------------|\n",
      "| train_fashion_369b0_00000 | RUNNING  | 192.168.0.135:481602 |          128 | 0.000330542 |   0.353592 |\n",
      "| train_fashion_369b0_00001 | RUNNING  | 192.168.0.135:481650 |           64 | 0.00186854  |   0.843826 |\n",
      "| train_fashion_369b0_00002 | RUNNING  | 192.168.0.135:481652 |          128 | 0.00029119  |   0.552573 |\n",
      "| train_fashion_369b0_00003 | RUNNING  | 192.168.0.135:481684 |          128 | 0.00043195  |   0.47837  |\n",
      "| train_fashion_369b0_00004 | PENDING  |                      |           16 | 0.00708167  |   0.769759 |\n",
      "| train_fashion_369b0_00005 | PENDING  |                      |           16 | 0.000162291 |   0.36995  |\n",
      "| train_fashion_369b0_00006 | PENDING  |                      |           64 | 0.00289137  |   0.818959 |\n",
      "| train_fashion_369b0_00007 | PENDING  |                      |           64 | 0.00169799  |   0.684505 |\n",
      "| train_fashion_369b0_00008 | PENDING  |                      |           16 | 0.00102337  |   0.700704 |\n",
      "| train_fashion_369b0_00009 | PENDING  |                      |           16 | 0.000636541 |   0.802663 |\n",
      "+---------------------------+----------+----------------------+--------------+-------------+------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<div class=\"trialProgress\">\n  <h3>Trial Progress</h3>\n  <table>\n<thead>\n<tr><th>Trial name               </th><th style=\"text-align: right;\">  accuracy</th><th>date               </th><th>done  </th><th>hostname   </th><th style=\"text-align: right;\">  iterations_since_restore</th><th style=\"text-align: right;\">   loss</th><th>node_ip      </th><th style=\"text-align: right;\">   pid</th><th>should_checkpoint  </th><th style=\"text-align: right;\">  time_since_restore</th><th style=\"text-align: right;\">  time_this_iter_s</th><th style=\"text-align: right;\">  time_total_s</th><th style=\"text-align: right;\">  timestamp</th><th style=\"text-align: right;\">  training_iteration</th><th>trial_id   </th></tr>\n</thead>\n<tbody>\n<tr><td>train_fashion_369b0_00000</td><td style=\"text-align: right;\">    0.1565</td><td>2023-05-14_14-58-14</td><td>False </td><td>jim-desktop</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">2.27271</td><td>192.168.0.135</td><td style=\"text-align: right;\">481602</td><td>True               </td><td style=\"text-align: right;\">             17.4771</td><td style=\"text-align: right;\">           17.4771</td><td style=\"text-align: right;\">       17.4771</td><td style=\"text-align: right;\"> 1684090694</td><td style=\"text-align: right;\">                   1</td><td>369b0_00000</td></tr>\n</tbody>\n</table>\n</div>\n<style>\n.trialProgress {\n  display: flex;\n  flex-direction: column;\n  color: var(--jp-ui-font-color1);\n}\n.trialProgress h3 {\n  font-weight: bold;\n}\n.trialProgress td {\n  white-space: nowrap;\n}\n</style>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-05-14 14:58:19 (running for 00:00:32.69)\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 2.000: None | Iter 1.000: -2.272705799416651\n",
      "Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/jim/ray_results/train_fashion_2023-05-14_14-57-40\n",
      "Number of trials: 10/10 (6 PENDING, 4 RUNNING)\n",
      "+---------------------------+----------+----------------------+--------------+-------------+------------+---------+------------+----------------------+\n",
      "| Trial name                | status   | loc                  |   batch_size |          lr |   momentum |    loss |   accuracy |   training_iteration |\n",
      "|---------------------------+----------+----------------------+--------------+-------------+------------+---------+------------+----------------------|\n",
      "| train_fashion_369b0_00000 | RUNNING  | 192.168.0.135:481602 |          128 | 0.000330542 |   0.353592 | 2.27271 |     0.1565 |                    1 |\n",
      "| train_fashion_369b0_00001 | RUNNING  | 192.168.0.135:481650 |           64 | 0.00186854  |   0.843826 |         |            |                      |\n",
      "| train_fashion_369b0_00002 | RUNNING  | 192.168.0.135:481652 |          128 | 0.00029119  |   0.552573 |         |            |                      |\n",
      "| train_fashion_369b0_00003 | RUNNING  | 192.168.0.135:481684 |          128 | 0.00043195  |   0.47837  |         |            |                      |\n",
      "| train_fashion_369b0_00004 | PENDING  |                      |           16 | 0.00708167  |   0.769759 |         |            |                      |\n",
      "| train_fashion_369b0_00005 | PENDING  |                      |           16 | 0.000162291 |   0.36995  |         |            |                      |\n",
      "| train_fashion_369b0_00006 | PENDING  |                      |           64 | 0.00289137  |   0.818959 |         |            |                      |\n",
      "| train_fashion_369b0_00007 | PENDING  |                      |           64 | 0.00169799  |   0.684505 |         |            |                      |\n",
      "| train_fashion_369b0_00008 | PENDING  |                      |           16 | 0.00102337  |   0.700704 |         |            |                      |\n",
      "| train_fashion_369b0_00009 | PENDING  |                      |           16 | 0.000636541 |   0.802663 |         |            |                      |\n",
      "+---------------------------+----------+----------------------+--------------+-------------+------------+---------+------------+----------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-05-14 14:58:28 (running for 00:00:42.36)\n",
      "Using AsyncHyperBand: num_stopped=2\n",
      "Bracket: Iter 2.000: None | Iter 1.000: -2.253447104103958\n",
      "Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/jim/ray_results/train_fashion_2023-05-14_14-57-40\n",
      "Number of trials: 10/10 (4 PENDING, 4 RUNNING, 2 TERMINATED)\n",
      "+---------------------------+------------+----------------------+--------------+-------------+------------+----------+------------+----------------------+\n",
      "| Trial name                | status     | loc                  |   batch_size |          lr |   momentum |     loss |   accuracy |   training_iteration |\n",
      "|---------------------------+------------+----------------------+--------------+-------------+------------+----------+------------+----------------------|\n",
      "| train_fashion_369b0_00000 | RUNNING    | 192.168.0.135:481602 |          128 | 0.000330542 |   0.353592 | 2.27271  |     0.1565 |                    1 |\n",
      "| train_fashion_369b0_00001 | RUNNING    | 192.168.0.135:481650 |           64 | 0.00186854  |   0.843826 | 0.757704 |     0.7253 |                    1 |\n",
      "| train_fashion_369b0_00004 | RUNNING    | 192.168.0.135:481684 |           16 | 0.00708167  |   0.769759 |          |            |                      |\n",
      "| train_fashion_369b0_00005 | RUNNING    | 192.168.0.135:481652 |           16 | 0.000162291 |   0.36995  |          |            |                      |\n",
      "| train_fashion_369b0_00006 | PENDING    |                      |           64 | 0.00289137  |   0.818959 |          |            |                      |\n",
      "| train_fashion_369b0_00007 | PENDING    |                      |           64 | 0.00169799  |   0.684505 |          |            |                      |\n",
      "| train_fashion_369b0_00008 | PENDING    |                      |           16 | 0.00102337  |   0.700704 |          |            |                      |\n",
      "| train_fashion_369b0_00009 | PENDING    |                      |           16 | 0.000636541 |   0.802663 |          |            |                      |\n",
      "| train_fashion_369b0_00002 | TERMINATED | 192.168.0.135:481652 |          128 | 0.00029119  |   0.552573 | 2.25731  |     0.2975 |                    1 |\n",
      "| train_fashion_369b0_00003 | TERMINATED | 192.168.0.135:481684 |          128 | 0.00043195  |   0.47837  | 2.24958  |     0.2619 |                    1 |\n",
      "+---------------------------+------------+----------------------+--------------+-------------+------------+----------+------------+----------------------+\n",
      "\n",
      "\n",
      "\u001B[2m\u001B[36m(train_fashion pid=481652)\u001B[0m [1,  2000] loss: 2.263\n",
      "== Status ==\n",
      "Current time: 2023-05-14 14:58:38 (running for 00:00:51.85)\n",
      "Using AsyncHyperBand: num_stopped=2\n",
      "Bracket: Iter 2.000: -2.2383686047566087 | Iter 1.000: -2.253447104103958\n",
      "Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/jim/ray_results/train_fashion_2023-05-14_14-57-40\n",
      "Number of trials: 10/10 (4 PENDING, 4 RUNNING, 2 TERMINATED)\n",
      "+---------------------------+------------+----------------------+--------------+-------------+------------+----------+------------+----------------------+\n",
      "| Trial name                | status     | loc                  |   batch_size |          lr |   momentum |     loss |   accuracy |   training_iteration |\n",
      "|---------------------------+------------+----------------------+--------------+-------------+------------+----------+------------+----------------------|\n",
      "| train_fashion_369b0_00000 | RUNNING    | 192.168.0.135:481602 |          128 | 0.000330542 |   0.353592 | 2.23837  |     0.1779 |                    2 |\n",
      "| train_fashion_369b0_00001 | RUNNING    | 192.168.0.135:481650 |           64 | 0.00186854  |   0.843826 | 0.757704 |     0.7253 |                    1 |\n",
      "| train_fashion_369b0_00004 | RUNNING    | 192.168.0.135:481684 |           16 | 0.00708167  |   0.769759 |          |            |                      |\n",
      "| train_fashion_369b0_00005 | RUNNING    | 192.168.0.135:481652 |           16 | 0.000162291 |   0.36995  |          |            |                      |\n",
      "| train_fashion_369b0_00006 | PENDING    |                      |           64 | 0.00289137  |   0.818959 |          |            |                      |\n",
      "| train_fashion_369b0_00007 | PENDING    |                      |           64 | 0.00169799  |   0.684505 |          |            |                      |\n",
      "| train_fashion_369b0_00008 | PENDING    |                      |           16 | 0.00102337  |   0.700704 |          |            |                      |\n",
      "| train_fashion_369b0_00009 | PENDING    |                      |           16 | 0.000636541 |   0.802663 |          |            |                      |\n",
      "| train_fashion_369b0_00002 | TERMINATED | 192.168.0.135:481652 |          128 | 0.00029119  |   0.552573 | 2.25731  |     0.2975 |                    1 |\n",
      "| train_fashion_369b0_00003 | TERMINATED | 192.168.0.135:481684 |          128 | 0.00043195  |   0.47837  | 2.24958  |     0.2619 |                    1 |\n",
      "+---------------------------+------------+----------------------+--------------+-------------+------------+----------+------------+----------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-05-14 14:58:43 (running for 00:00:56.85)\n",
      "Using AsyncHyperBand: num_stopped=2\n",
      "Bracket: Iter 2.000: -2.2383686047566087 | Iter 1.000: -2.253447104103958\n",
      "Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/jim/ray_results/train_fashion_2023-05-14_14-57-40\n",
      "Number of trials: 10/10 (4 PENDING, 4 RUNNING, 2 TERMINATED)\n",
      "+---------------------------+------------+----------------------+--------------+-------------+------------+----------+------------+----------------------+\n",
      "| Trial name                | status     | loc                  |   batch_size |          lr |   momentum |     loss |   accuracy |   training_iteration |\n",
      "|---------------------------+------------+----------------------+--------------+-------------+------------+----------+------------+----------------------|\n",
      "| train_fashion_369b0_00000 | RUNNING    | 192.168.0.135:481602 |          128 | 0.000330542 |   0.353592 | 2.23837  |     0.1779 |                    2 |\n",
      "| train_fashion_369b0_00001 | RUNNING    | 192.168.0.135:481650 |           64 | 0.00186854  |   0.843826 | 0.757704 |     0.7253 |                    1 |\n",
      "| train_fashion_369b0_00004 | RUNNING    | 192.168.0.135:481684 |           16 | 0.00708167  |   0.769759 |          |            |                      |\n",
      "| train_fashion_369b0_00005 | RUNNING    | 192.168.0.135:481652 |           16 | 0.000162291 |   0.36995  |          |            |                      |\n",
      "| train_fashion_369b0_00006 | PENDING    |                      |           64 | 0.00289137  |   0.818959 |          |            |                      |\n",
      "| train_fashion_369b0_00007 | PENDING    |                      |           64 | 0.00169799  |   0.684505 |          |            |                      |\n",
      "| train_fashion_369b0_00008 | PENDING    |                      |           16 | 0.00102337  |   0.700704 |          |            |                      |\n",
      "| train_fashion_369b0_00009 | PENDING    |                      |           16 | 0.000636541 |   0.802663 |          |            |                      |\n",
      "| train_fashion_369b0_00002 | TERMINATED | 192.168.0.135:481652 |          128 | 0.00029119  |   0.552573 | 2.25731  |     0.2975 |                    1 |\n",
      "| train_fashion_369b0_00003 | TERMINATED | 192.168.0.135:481684 |          128 | 0.00043195  |   0.47837  | 2.24958  |     0.2619 |                    1 |\n",
      "+---------------------------+------------+----------------------+--------------+-------------+------------+----------+------------+----------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-05-14 14:58:49 (running for 00:01:03.07)\n",
      "Using AsyncHyperBand: num_stopped=2\n",
      "Bracket: Iter 2.000: -1.4193743742443155 | Iter 1.000: -2.253447104103958\n",
      "Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/jim/ray_results/train_fashion_2023-05-14_14-57-40\n",
      "Number of trials: 10/10 (4 PENDING, 4 RUNNING, 2 TERMINATED)\n",
      "+---------------------------+------------+----------------------+--------------+-------------+------------+---------+------------+----------------------+\n",
      "| Trial name                | status     | loc                  |   batch_size |          lr |   momentum |    loss |   accuracy |   training_iteration |\n",
      "|---------------------------+------------+----------------------+--------------+-------------+------------+---------+------------+----------------------|\n",
      "| train_fashion_369b0_00000 | RUNNING    | 192.168.0.135:481602 |          128 | 0.000330542 |   0.353592 | 2.23837 |     0.1779 |                    2 |\n",
      "| train_fashion_369b0_00001 | RUNNING    | 192.168.0.135:481650 |           64 | 0.00186854  |   0.843826 | 0.60038 |     0.7876 |                    2 |\n",
      "| train_fashion_369b0_00004 | RUNNING    | 192.168.0.135:481684 |           16 | 0.00708167  |   0.769759 |         |            |                      |\n",
      "| train_fashion_369b0_00005 | RUNNING    | 192.168.0.135:481652 |           16 | 0.000162291 |   0.36995  |         |            |                      |\n",
      "| train_fashion_369b0_00006 | PENDING    |                      |           64 | 0.00289137  |   0.818959 |         |            |                      |\n",
      "| train_fashion_369b0_00007 | PENDING    |                      |           64 | 0.00169799  |   0.684505 |         |            |                      |\n",
      "| train_fashion_369b0_00008 | PENDING    |                      |           16 | 0.00102337  |   0.700704 |         |            |                      |\n",
      "| train_fashion_369b0_00009 | PENDING    |                      |           16 | 0.000636541 |   0.802663 |         |            |                      |\n",
      "| train_fashion_369b0_00002 | TERMINATED | 192.168.0.135:481652 |          128 | 0.00029119  |   0.552573 | 2.25731 |     0.2975 |                    1 |\n",
      "| train_fashion_369b0_00003 | TERMINATED | 192.168.0.135:481684 |          128 | 0.00043195  |   0.47837  | 2.24958 |     0.2619 |                    1 |\n",
      "+---------------------------+------------+----------------------+--------------+-------------+------------+---------+------------+----------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-05-14 14:58:58 (running for 00:01:12.21)\n",
      "Using AsyncHyperBand: num_stopped=3\n",
      "Bracket: Iter 2.000: -1.4193743742443155 | Iter 1.000: -2.19204009042088\n",
      "Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/jim/ray_results/train_fashion_2023-05-14_14-57-40\n",
      "Number of trials: 10/10 (3 PENDING, 4 RUNNING, 3 TERMINATED)\n",
      "+---------------------------+------------+----------------------+--------------+-------------+------------+----------+------------+----------------------+\n",
      "| Trial name                | status     | loc                  |   batch_size |          lr |   momentum |     loss |   accuracy |   training_iteration |\n",
      "|---------------------------+------------+----------------------+--------------+-------------+------------+----------+------------+----------------------|\n",
      "| train_fashion_369b0_00001 | RUNNING    | 192.168.0.135:481650 |           64 | 0.00186854  |   0.843826 | 0.60038  |     0.7876 |                    2 |\n",
      "| train_fashion_369b0_00004 | RUNNING    | 192.168.0.135:481684 |           16 | 0.00708167  |   0.769759 | 0.499316 |     0.8257 |                    1 |\n",
      "| train_fashion_369b0_00005 | RUNNING    | 192.168.0.135:481652 |           16 | 0.000162291 |   0.36995  | 2.1345   |     0.4046 |                    1 |\n",
      "| train_fashion_369b0_00006 | RUNNING    | 192.168.0.135:481602 |           64 | 0.00289137  |   0.818959 |          |            |                      |\n",
      "| train_fashion_369b0_00007 | PENDING    |                      |           64 | 0.00169799  |   0.684505 |          |            |                      |\n",
      "| train_fashion_369b0_00008 | PENDING    |                      |           16 | 0.00102337  |   0.700704 |          |            |                      |\n",
      "| train_fashion_369b0_00009 | PENDING    |                      |           16 | 0.000636541 |   0.802663 |          |            |                      |\n",
      "| train_fashion_369b0_00000 | TERMINATED | 192.168.0.135:481602 |          128 | 0.000330542 |   0.353592 | 2.20102  |     0.2912 |                    3 |\n",
      "| train_fashion_369b0_00002 | TERMINATED | 192.168.0.135:481652 |          128 | 0.00029119  |   0.552573 | 2.25731  |     0.2975 |                    1 |\n",
      "| train_fashion_369b0_00003 | TERMINATED | 192.168.0.135:481684 |          128 | 0.00043195  |   0.47837  | 2.24958  |     0.2619 |                    1 |\n",
      "+---------------------------+------------+----------------------+--------------+-------------+------------+----------+------------+----------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-05-14 14:59:03 (running for 00:01:17.22)\n",
      "Using AsyncHyperBand: num_stopped=3\n",
      "Bracket: Iter 2.000: -1.4193743742443155 | Iter 1.000: -2.19204009042088\n",
      "Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/jim/ray_results/train_fashion_2023-05-14_14-57-40\n",
      "Number of trials: 10/10 (3 PENDING, 4 RUNNING, 3 TERMINATED)\n",
      "+---------------------------+------------+----------------------+--------------+-------------+------------+----------+------------+----------------------+\n",
      "| Trial name                | status     | loc                  |   batch_size |          lr |   momentum |     loss |   accuracy |   training_iteration |\n",
      "|---------------------------+------------+----------------------+--------------+-------------+------------+----------+------------+----------------------|\n",
      "| train_fashion_369b0_00001 | RUNNING    | 192.168.0.135:481650 |           64 | 0.00186854  |   0.843826 | 0.60038  |     0.7876 |                    2 |\n",
      "| train_fashion_369b0_00004 | RUNNING    | 192.168.0.135:481684 |           16 | 0.00708167  |   0.769759 | 0.499316 |     0.8257 |                    1 |\n",
      "| train_fashion_369b0_00005 | RUNNING    | 192.168.0.135:481652 |           16 | 0.000162291 |   0.36995  | 2.1345   |     0.4046 |                    1 |\n",
      "| train_fashion_369b0_00006 | RUNNING    | 192.168.0.135:481602 |           64 | 0.00289137  |   0.818959 |          |            |                      |\n",
      "| train_fashion_369b0_00007 | PENDING    |                      |           64 | 0.00169799  |   0.684505 |          |            |                      |\n",
      "| train_fashion_369b0_00008 | PENDING    |                      |           16 | 0.00102337  |   0.700704 |          |            |                      |\n",
      "| train_fashion_369b0_00009 | PENDING    |                      |           16 | 0.000636541 |   0.802663 |          |            |                      |\n",
      "| train_fashion_369b0_00000 | TERMINATED | 192.168.0.135:481602 |          128 | 0.000330542 |   0.353592 | 2.20102  |     0.2912 |                    3 |\n",
      "| train_fashion_369b0_00002 | TERMINATED | 192.168.0.135:481652 |          128 | 0.00029119  |   0.552573 | 2.25731  |     0.2975 |                    1 |\n",
      "| train_fashion_369b0_00003 | TERMINATED | 192.168.0.135:481684 |          128 | 0.00043195  |   0.47837  | 2.24958  |     0.2619 |                    1 |\n",
      "+---------------------------+------------+----------------------+--------------+-------------+------------+----------+------------+----------------------+\n",
      "\n",
      "\n",
      "\u001B[2m\u001B[36m(train_fashion pid=481684)\u001B[0m [2,  2000] loss: 0.415\u001B[32m [repeated 2x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001B[0m\n",
      "== Status ==\n",
      "Current time: 2023-05-14 14:59:09 (running for 00:01:23.24)\n",
      "Using AsyncHyperBand: num_stopped=4\n",
      "Bracket: Iter 2.000: -1.4193743742443155 | Iter 1.000: -2.19204009042088\n",
      "Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/jim/ray_results/train_fashion_2023-05-14_14-57-40\n",
      "Number of trials: 10/10 (2 PENDING, 4 RUNNING, 4 TERMINATED)\n",
      "+---------------------------+------------+----------------------+--------------+-------------+------------+----------+------------+----------------------+\n",
      "| Trial name                | status     | loc                  |   batch_size |          lr |   momentum |     loss |   accuracy |   training_iteration |\n",
      "|---------------------------+------------+----------------------+--------------+-------------+------------+----------+------------+----------------------|\n",
      "| train_fashion_369b0_00004 | RUNNING    | 192.168.0.135:481684 |           16 | 0.00708167  |   0.769759 | 0.499316 |     0.8257 |                    1 |\n",
      "| train_fashion_369b0_00005 | RUNNING    | 192.168.0.135:481652 |           16 | 0.000162291 |   0.36995  | 2.1345   |     0.4046 |                    1 |\n",
      "| train_fashion_369b0_00006 | RUNNING    | 192.168.0.135:481602 |           64 | 0.00289137  |   0.818959 |          |            |                      |\n",
      "| train_fashion_369b0_00007 | RUNNING    | 192.168.0.135:481650 |           64 | 0.00169799  |   0.684505 |          |            |                      |\n",
      "| train_fashion_369b0_00008 | PENDING    |                      |           16 | 0.00102337  |   0.700704 |          |            |                      |\n",
      "| train_fashion_369b0_00009 | PENDING    |                      |           16 | 0.000636541 |   0.802663 |          |            |                      |\n",
      "| train_fashion_369b0_00000 | TERMINATED | 192.168.0.135:481602 |          128 | 0.000330542 |   0.353592 | 2.20102  |     0.2912 |                    3 |\n",
      "| train_fashion_369b0_00001 | TERMINATED | 192.168.0.135:481650 |           64 | 0.00186854  |   0.843826 | 0.53785  |     0.809  |                    3 |\n",
      "| train_fashion_369b0_00002 | TERMINATED | 192.168.0.135:481652 |          128 | 0.00029119  |   0.552573 | 2.25731  |     0.2975 |                    1 |\n",
      "| train_fashion_369b0_00003 | TERMINATED | 192.168.0.135:481684 |          128 | 0.00043195  |   0.47837  | 2.24958  |     0.2619 |                    1 |\n",
      "+---------------------------+------------+----------------------+--------------+-------------+------------+----------+------------+----------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-05-14 14:59:14 (running for 00:01:28.25)\n",
      "Using AsyncHyperBand: num_stopped=4\n",
      "Bracket: Iter 2.000: -1.4193743742443155 | Iter 1.000: -2.19204009042088\n",
      "Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/jim/ray_results/train_fashion_2023-05-14_14-57-40\n",
      "Number of trials: 10/10 (2 PENDING, 4 RUNNING, 4 TERMINATED)\n",
      "+---------------------------+------------+----------------------+--------------+-------------+------------+----------+------------+----------------------+\n",
      "| Trial name                | status     | loc                  |   batch_size |          lr |   momentum |     loss |   accuracy |   training_iteration |\n",
      "|---------------------------+------------+----------------------+--------------+-------------+------------+----------+------------+----------------------|\n",
      "| train_fashion_369b0_00004 | RUNNING    | 192.168.0.135:481684 |           16 | 0.00708167  |   0.769759 | 0.499316 |     0.8257 |                    1 |\n",
      "| train_fashion_369b0_00005 | RUNNING    | 192.168.0.135:481652 |           16 | 0.000162291 |   0.36995  | 2.1345   |     0.4046 |                    1 |\n",
      "| train_fashion_369b0_00006 | RUNNING    | 192.168.0.135:481602 |           64 | 0.00289137  |   0.818959 |          |            |                      |\n",
      "| train_fashion_369b0_00007 | RUNNING    | 192.168.0.135:481650 |           64 | 0.00169799  |   0.684505 |          |            |                      |\n",
      "| train_fashion_369b0_00008 | PENDING    |                      |           16 | 0.00102337  |   0.700704 |          |            |                      |\n",
      "| train_fashion_369b0_00009 | PENDING    |                      |           16 | 0.000636541 |   0.802663 |          |            |                      |\n",
      "| train_fashion_369b0_00000 | TERMINATED | 192.168.0.135:481602 |          128 | 0.000330542 |   0.353592 | 2.20102  |     0.2912 |                    3 |\n",
      "| train_fashion_369b0_00001 | TERMINATED | 192.168.0.135:481650 |           64 | 0.00186854  |   0.843826 | 0.53785  |     0.809  |                    3 |\n",
      "| train_fashion_369b0_00002 | TERMINATED | 192.168.0.135:481652 |          128 | 0.00029119  |   0.552573 | 2.25731  |     0.2975 |                    1 |\n",
      "| train_fashion_369b0_00003 | TERMINATED | 192.168.0.135:481684 |          128 | 0.00043195  |   0.47837  | 2.24958  |     0.2619 |                    1 |\n",
      "+---------------------------+------------+----------------------+--------------+-------------+------------+----------+------------+----------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-05-14 14:59:20 (running for 00:01:34.28)\n",
      "Using AsyncHyperBand: num_stopped=4\n",
      "Bracket: Iter 2.000: -1.4193743742443155 | Iter 1.000: -2.1344995681762695\n",
      "Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/jim/ray_results/train_fashion_2023-05-14_14-57-40\n",
      "Number of trials: 10/10 (2 PENDING, 4 RUNNING, 4 TERMINATED)\n",
      "+---------------------------+------------+----------------------+--------------+-------------+------------+----------+------------+----------------------+\n",
      "| Trial name                | status     | loc                  |   batch_size |          lr |   momentum |     loss |   accuracy |   training_iteration |\n",
      "|---------------------------+------------+----------------------+--------------+-------------+------------+----------+------------+----------------------|\n",
      "| train_fashion_369b0_00004 | RUNNING    | 192.168.0.135:481684 |           16 | 0.00708167  |   0.769759 | 0.499316 |     0.8257 |                    1 |\n",
      "| train_fashion_369b0_00005 | RUNNING    | 192.168.0.135:481652 |           16 | 0.000162291 |   0.36995  | 2.1345   |     0.4046 |                    1 |\n",
      "| train_fashion_369b0_00006 | RUNNING    | 192.168.0.135:481602 |           64 | 0.00289137  |   0.818959 | 0.677064 |     0.7576 |                    1 |\n",
      "| train_fashion_369b0_00007 | RUNNING    | 192.168.0.135:481650 |           64 | 0.00169799  |   0.684505 |          |            |                      |\n",
      "| train_fashion_369b0_00008 | PENDING    |                      |           16 | 0.00102337  |   0.700704 |          |            |                      |\n",
      "| train_fashion_369b0_00009 | PENDING    |                      |           16 | 0.000636541 |   0.802663 |          |            |                      |\n",
      "| train_fashion_369b0_00000 | TERMINATED | 192.168.0.135:481602 |          128 | 0.000330542 |   0.353592 | 2.20102  |     0.2912 |                    3 |\n",
      "| train_fashion_369b0_00001 | TERMINATED | 192.168.0.135:481650 |           64 | 0.00186854  |   0.843826 | 0.53785  |     0.809  |                    3 |\n",
      "| train_fashion_369b0_00002 | TERMINATED | 192.168.0.135:481652 |          128 | 0.00029119  |   0.552573 | 2.25731  |     0.2975 |                    1 |\n",
      "| train_fashion_369b0_00003 | TERMINATED | 192.168.0.135:481684 |          128 | 0.00043195  |   0.47837  | 2.24958  |     0.2619 |                    1 |\n",
      "+---------------------------+------------+----------------------+--------------+-------------+------------+----------+------------+----------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-05-14 14:59:27 (running for 00:01:40.73)\n",
      "Using AsyncHyperBand: num_stopped=5\n",
      "Bracket: Iter 2.000: -1.2150885808915848 | Iter 1.000: -1.5907635998631737\n",
      "Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/jim/ray_results/train_fashion_2023-05-14_14-57-40\n",
      "Number of trials: 10/10 (1 PENDING, 4 RUNNING, 5 TERMINATED)\n",
      "+---------------------------+------------+----------------------+--------------+-------------+------------+----------+------------+----------------------+\n",
      "| Trial name                | status     | loc                  |   batch_size |          lr |   momentum |     loss |   accuracy |   training_iteration |\n",
      "|---------------------------+------------+----------------------+--------------+-------------+------------+----------+------------+----------------------|\n",
      "| train_fashion_369b0_00004 | RUNNING    | 192.168.0.135:481684 |           16 | 0.00708167  |   0.769759 | 0.430207 |     0.8443 |                    2 |\n",
      "| train_fashion_369b0_00006 | RUNNING    | 192.168.0.135:481602 |           64 | 0.00289137  |   0.818959 | 0.677064 |     0.7576 |                    1 |\n",
      "| train_fashion_369b0_00007 | RUNNING    | 192.168.0.135:481650 |           64 | 0.00169799  |   0.684505 | 1.04703  |     0.6516 |                    1 |\n",
      "| train_fashion_369b0_00008 | RUNNING    | 192.168.0.135:481652 |           16 | 0.00102337  |   0.700704 |          |            |                      |\n",
      "| train_fashion_369b0_00009 | PENDING    |                      |           16 | 0.000636541 |   0.802663 |          |            |                      |\n",
      "| train_fashion_369b0_00000 | TERMINATED | 192.168.0.135:481602 |          128 | 0.000330542 |   0.353592 | 2.20102  |     0.2912 |                    3 |\n",
      "| train_fashion_369b0_00001 | TERMINATED | 192.168.0.135:481650 |           64 | 0.00186854  |   0.843826 | 0.53785  |     0.809  |                    3 |\n",
      "| train_fashion_369b0_00002 | TERMINATED | 192.168.0.135:481652 |          128 | 0.00029119  |   0.552573 | 2.25731  |     0.2975 |                    1 |\n",
      "| train_fashion_369b0_00003 | TERMINATED | 192.168.0.135:481684 |          128 | 0.00043195  |   0.47837  | 2.24958  |     0.2619 |                    1 |\n",
      "| train_fashion_369b0_00005 | TERMINATED | 192.168.0.135:481652 |           16 | 0.000162291 |   0.36995  | 1.8298   |     0.5789 |                    2 |\n",
      "+---------------------------+------------+----------------------+--------------+-------------+------------+----------+------------+----------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-05-14 14:59:32 (running for 00:01:45.74)\n",
      "Using AsyncHyperBand: num_stopped=5\n",
      "Bracket: Iter 2.000: -1.2150885808915848 | Iter 1.000: -1.5907635998631737\n",
      "Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/jim/ray_results/train_fashion_2023-05-14_14-57-40\n",
      "Number of trials: 10/10 (1 PENDING, 4 RUNNING, 5 TERMINATED)\n",
      "+---------------------------+------------+----------------------+--------------+-------------+------------+----------+------------+----------------------+\n",
      "| Trial name                | status     | loc                  |   batch_size |          lr |   momentum |     loss |   accuracy |   training_iteration |\n",
      "|---------------------------+------------+----------------------+--------------+-------------+------------+----------+------------+----------------------|\n",
      "| train_fashion_369b0_00004 | RUNNING    | 192.168.0.135:481684 |           16 | 0.00708167  |   0.769759 | 0.430207 |     0.8443 |                    2 |\n",
      "| train_fashion_369b0_00006 | RUNNING    | 192.168.0.135:481602 |           64 | 0.00289137  |   0.818959 | 0.677064 |     0.7576 |                    1 |\n",
      "| train_fashion_369b0_00007 | RUNNING    | 192.168.0.135:481650 |           64 | 0.00169799  |   0.684505 | 1.04703  |     0.6516 |                    1 |\n",
      "| train_fashion_369b0_00008 | RUNNING    | 192.168.0.135:481652 |           16 | 0.00102337  |   0.700704 |          |            |                      |\n",
      "| train_fashion_369b0_00009 | PENDING    |                      |           16 | 0.000636541 |   0.802663 |          |            |                      |\n",
      "| train_fashion_369b0_00000 | TERMINATED | 192.168.0.135:481602 |          128 | 0.000330542 |   0.353592 | 2.20102  |     0.2912 |                    3 |\n",
      "| train_fashion_369b0_00001 | TERMINATED | 192.168.0.135:481650 |           64 | 0.00186854  |   0.843826 | 0.53785  |     0.809  |                    3 |\n",
      "| train_fashion_369b0_00002 | TERMINATED | 192.168.0.135:481652 |          128 | 0.00029119  |   0.552573 | 2.25731  |     0.2975 |                    1 |\n",
      "| train_fashion_369b0_00003 | TERMINATED | 192.168.0.135:481684 |          128 | 0.00043195  |   0.47837  | 2.24958  |     0.2619 |                    1 |\n",
      "| train_fashion_369b0_00005 | TERMINATED | 192.168.0.135:481652 |           16 | 0.000162291 |   0.36995  | 1.8298   |     0.5789 |                    2 |\n",
      "+---------------------------+------------+----------------------+--------------+-------------+------------+----------+------------+----------------------+\n",
      "\n",
      "\n",
      "\u001B[2m\u001B[36m(train_fashion pid=481684)\u001B[0m [3,  2000] loss: 0.363\u001B[32m [repeated 2x across cluster]\u001B[0m\n",
      "== Status ==\n",
      "Current time: 2023-05-14 14:59:40 (running for 00:01:54.49)\n",
      "Using AsyncHyperBand: num_stopped=5\n",
      "Bracket: Iter 2.000: -0.6003801437320223 | Iter 1.000: -1.5907635998631737\n",
      "Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/jim/ray_results/train_fashion_2023-05-14_14-57-40\n",
      "Number of trials: 10/10 (1 PENDING, 4 RUNNING, 5 TERMINATED)\n",
      "+---------------------------+------------+----------------------+--------------+-------------+------------+----------+------------+----------------------+\n",
      "| Trial name                | status     | loc                  |   batch_size |          lr |   momentum |     loss |   accuracy |   training_iteration |\n",
      "|---------------------------+------------+----------------------+--------------+-------------+------------+----------+------------+----------------------|\n",
      "| train_fashion_369b0_00004 | RUNNING    | 192.168.0.135:481684 |           16 | 0.00708167  |   0.769759 | 0.430207 |     0.8443 |                    2 |\n",
      "| train_fashion_369b0_00006 | RUNNING    | 192.168.0.135:481602 |           64 | 0.00289137  |   0.818959 | 0.551989 |     0.806  |                    2 |\n",
      "| train_fashion_369b0_00007 | RUNNING    | 192.168.0.135:481650 |           64 | 0.00169799  |   0.684505 | 1.04703  |     0.6516 |                    1 |\n",
      "| train_fashion_369b0_00008 | RUNNING    | 192.168.0.135:481652 |           16 | 0.00102337  |   0.700704 |          |            |                      |\n",
      "| train_fashion_369b0_00009 | PENDING    |                      |           16 | 0.000636541 |   0.802663 |          |            |                      |\n",
      "| train_fashion_369b0_00000 | TERMINATED | 192.168.0.135:481602 |          128 | 0.000330542 |   0.353592 | 2.20102  |     0.2912 |                    3 |\n",
      "| train_fashion_369b0_00001 | TERMINATED | 192.168.0.135:481650 |           64 | 0.00186854  |   0.843826 | 0.53785  |     0.809  |                    3 |\n",
      "| train_fashion_369b0_00002 | TERMINATED | 192.168.0.135:481652 |          128 | 0.00029119  |   0.552573 | 2.25731  |     0.2975 |                    1 |\n",
      "| train_fashion_369b0_00003 | TERMINATED | 192.168.0.135:481684 |          128 | 0.00043195  |   0.47837  | 2.24958  |     0.2619 |                    1 |\n",
      "| train_fashion_369b0_00005 | TERMINATED | 192.168.0.135:481652 |           16 | 0.000162291 |   0.36995  | 1.8298   |     0.5789 |                    2 |\n",
      "+---------------------------+------------+----------------------+--------------+-------------+------------+----------+------------+----------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-05-14 14:59:45 (running for 00:01:59.49)\n",
      "Using AsyncHyperBand: num_stopped=5\n",
      "Bracket: Iter 2.000: -0.6003801437320223 | Iter 1.000: -1.5907635998631737\n",
      "Logical resource usage: 16.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/jim/ray_results/train_fashion_2023-05-14_14-57-40\n",
      "Number of trials: 10/10 (1 PENDING, 4 RUNNING, 5 TERMINATED)\n",
      "+---------------------------+------------+----------------------+--------------+-------------+------------+----------+------------+----------------------+\n",
      "| Trial name                | status     | loc                  |   batch_size |          lr |   momentum |     loss |   accuracy |   training_iteration |\n",
      "|---------------------------+------------+----------------------+--------------+-------------+------------+----------+------------+----------------------|\n",
      "| train_fashion_369b0_00004 | RUNNING    | 192.168.0.135:481684 |           16 | 0.00708167  |   0.769759 | 0.430207 |     0.8443 |                    2 |\n",
      "| train_fashion_369b0_00006 | RUNNING    | 192.168.0.135:481602 |           64 | 0.00289137  |   0.818959 | 0.551989 |     0.806  |                    2 |\n",
      "| train_fashion_369b0_00007 | RUNNING    | 192.168.0.135:481650 |           64 | 0.00169799  |   0.684505 | 1.04703  |     0.6516 |                    1 |\n",
      "| train_fashion_369b0_00008 | RUNNING    | 192.168.0.135:481652 |           16 | 0.00102337  |   0.700704 |          |            |                      |\n",
      "| train_fashion_369b0_00009 | PENDING    |                      |           16 | 0.000636541 |   0.802663 |          |            |                      |\n",
      "| train_fashion_369b0_00000 | TERMINATED | 192.168.0.135:481602 |          128 | 0.000330542 |   0.353592 | 2.20102  |     0.2912 |                    3 |\n",
      "| train_fashion_369b0_00001 | TERMINATED | 192.168.0.135:481650 |           64 | 0.00186854  |   0.843826 | 0.53785  |     0.809  |                    3 |\n",
      "| train_fashion_369b0_00002 | TERMINATED | 192.168.0.135:481652 |          128 | 0.00029119  |   0.552573 | 2.25731  |     0.2975 |                    1 |\n",
      "| train_fashion_369b0_00003 | TERMINATED | 192.168.0.135:481684 |          128 | 0.00043195  |   0.47837  | 2.24958  |     0.2619 |                    1 |\n",
      "| train_fashion_369b0_00005 | TERMINATED | 192.168.0.135:481652 |           16 | 0.000162291 |   0.36995  | 1.8298   |     0.5789 |                    2 |\n",
      "+---------------------------+------------+----------------------+--------------+-------------+------------+----------+------------+----------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-05-14 14:59:52 (running for 00:02:05.97)\n",
      "Using AsyncHyperBand: num_stopped=7\n",
      "Bracket: Iter 2.000: -0.6855285065189289 | Iter 1.000: -1.0470276315500782\n",
      "Logical resource usage: 12.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/jim/ray_results/train_fashion_2023-05-14_14-57-40\n",
      "Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)\n",
      "+---------------------------+------------+----------------------+--------------+-------------+------------+----------+------------+----------------------+\n",
      "| Trial name                | status     | loc                  |   batch_size |          lr |   momentum |     loss |   accuracy |   training_iteration |\n",
      "|---------------------------+------------+----------------------+--------------+-------------+------------+----------+------------+----------------------|\n",
      "| train_fashion_369b0_00006 | RUNNING    | 192.168.0.135:481602 |           64 | 0.00289137  |   0.818959 | 0.551989 |     0.806  |                    2 |\n",
      "| train_fashion_369b0_00008 | RUNNING    | 192.168.0.135:481652 |           16 | 0.00102337  |   0.700704 | 0.72156  |     0.7323 |                    1 |\n",
      "| train_fashion_369b0_00009 | RUNNING    | 192.168.0.135:481650 |           16 | 0.000636541 |   0.802663 |          |            |                      |\n",
      "| train_fashion_369b0_00000 | TERMINATED | 192.168.0.135:481602 |          128 | 0.000330542 |   0.353592 | 2.20102  |     0.2912 |                    3 |\n",
      "| train_fashion_369b0_00001 | TERMINATED | 192.168.0.135:481650 |           64 | 0.00186854  |   0.843826 | 0.53785  |     0.809  |                    3 |\n",
      "| train_fashion_369b0_00002 | TERMINATED | 192.168.0.135:481652 |          128 | 0.00029119  |   0.552573 | 2.25731  |     0.2975 |                    1 |\n",
      "| train_fashion_369b0_00003 | TERMINATED | 192.168.0.135:481684 |          128 | 0.00043195  |   0.47837  | 2.24958  |     0.2619 |                    1 |\n",
      "| train_fashion_369b0_00004 | TERMINATED | 192.168.0.135:481684 |           16 | 0.00708167  |   0.769759 | 0.399538 |     0.8551 |                    3 |\n",
      "| train_fashion_369b0_00005 | TERMINATED | 192.168.0.135:481652 |           16 | 0.000162291 |   0.36995  | 1.8298   |     0.5789 |                    2 |\n",
      "| train_fashion_369b0_00007 | TERMINATED | 192.168.0.135:481650 |           64 | 0.00169799  |   0.684505 | 0.770677 |     0.7151 |                    2 |\n",
      "+---------------------------+------------+----------------------+--------------+-------------+------------+----------+------------+----------------------+\n",
      "\n",
      "\n",
      "\u001B[2m\u001B[36m(train_fashion pid=481650)\u001B[0m [1,  2000] loss: 1.535\u001B[32m [repeated 2x across cluster]\u001B[0m\n",
      "== Status ==\n",
      "Current time: 2023-05-14 15:00:01 (running for 00:02:15.56)\n",
      "Using AsyncHyperBand: num_stopped=8\n",
      "Bracket: Iter 2.000: -0.6855285065189289 | Iter 1.000: -1.0470276315500782\n",
      "Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/jim/ray_results/train_fashion_2023-05-14_14-57-40\n",
      "Number of trials: 10/10 (2 RUNNING, 8 TERMINATED)\n",
      "+---------------------------+------------+----------------------+--------------+-------------+------------+----------+------------+----------------------+\n",
      "| Trial name                | status     | loc                  |   batch_size |          lr |   momentum |     loss |   accuracy |   training_iteration |\n",
      "|---------------------------+------------+----------------------+--------------+-------------+------------+----------+------------+----------------------|\n",
      "| train_fashion_369b0_00008 | RUNNING    | 192.168.0.135:481652 |           16 | 0.00102337  |   0.700704 | 0.72156  |     0.7323 |                    1 |\n",
      "| train_fashion_369b0_00009 | RUNNING    | 192.168.0.135:481650 |           16 | 0.000636541 |   0.802663 |          |            |                      |\n",
      "| train_fashion_369b0_00000 | TERMINATED | 192.168.0.135:481602 |          128 | 0.000330542 |   0.353592 | 2.20102  |     0.2912 |                    3 |\n",
      "| train_fashion_369b0_00001 | TERMINATED | 192.168.0.135:481650 |           64 | 0.00186854  |   0.843826 | 0.53785  |     0.809  |                    3 |\n",
      "| train_fashion_369b0_00002 | TERMINATED | 192.168.0.135:481652 |          128 | 0.00029119  |   0.552573 | 2.25731  |     0.2975 |                    1 |\n",
      "| train_fashion_369b0_00003 | TERMINATED | 192.168.0.135:481684 |          128 | 0.00043195  |   0.47837  | 2.24958  |     0.2619 |                    1 |\n",
      "| train_fashion_369b0_00004 | TERMINATED | 192.168.0.135:481684 |           16 | 0.00708167  |   0.769759 | 0.399538 |     0.8551 |                    3 |\n",
      "| train_fashion_369b0_00005 | TERMINATED | 192.168.0.135:481652 |           16 | 0.000162291 |   0.36995  | 1.8298   |     0.5789 |                    2 |\n",
      "| train_fashion_369b0_00006 | TERMINATED | 192.168.0.135:481602 |           64 | 0.00289137  |   0.818959 | 0.507381 |     0.8213 |                    3 |\n",
      "| train_fashion_369b0_00007 | TERMINATED | 192.168.0.135:481650 |           64 | 0.00169799  |   0.684505 | 0.770677 |     0.7151 |                    2 |\n",
      "+---------------------------+------------+----------------------+--------------+-------------+------------+----------+------------+----------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-05-14 15:00:07 (running for 00:02:21.59)\n",
      "Using AsyncHyperBand: num_stopped=8\n",
      "Bracket: Iter 2.000: -0.6003801437320223 | Iter 1.000: -0.9023655880788329\n",
      "Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/jim/ray_results/train_fashion_2023-05-14_14-57-40\n",
      "Number of trials: 10/10 (2 RUNNING, 8 TERMINATED)\n",
      "+---------------------------+------------+----------------------+--------------+-------------+------------+----------+------------+----------------------+\n",
      "| Trial name                | status     | loc                  |   batch_size |          lr |   momentum |     loss |   accuracy |   training_iteration |\n",
      "|---------------------------+------------+----------------------+--------------+-------------+------------+----------+------------+----------------------|\n",
      "| train_fashion_369b0_00008 | RUNNING    | 192.168.0.135:481652 |           16 | 0.00102337  |   0.700704 | 0.575693 |     0.7977 |                    2 |\n",
      "| train_fashion_369b0_00009 | RUNNING    | 192.168.0.135:481650 |           16 | 0.000636541 |   0.802663 | 0.731827 |     0.7259 |                    1 |\n",
      "| train_fashion_369b0_00000 | TERMINATED | 192.168.0.135:481602 |          128 | 0.000330542 |   0.353592 | 2.20102  |     0.2912 |                    3 |\n",
      "| train_fashion_369b0_00001 | TERMINATED | 192.168.0.135:481650 |           64 | 0.00186854  |   0.843826 | 0.53785  |     0.809  |                    3 |\n",
      "| train_fashion_369b0_00002 | TERMINATED | 192.168.0.135:481652 |          128 | 0.00029119  |   0.552573 | 2.25731  |     0.2975 |                    1 |\n",
      "| train_fashion_369b0_00003 | TERMINATED | 192.168.0.135:481684 |          128 | 0.00043195  |   0.47837  | 2.24958  |     0.2619 |                    1 |\n",
      "| train_fashion_369b0_00004 | TERMINATED | 192.168.0.135:481684 |           16 | 0.00708167  |   0.769759 | 0.399538 |     0.8551 |                    3 |\n",
      "| train_fashion_369b0_00005 | TERMINATED | 192.168.0.135:481652 |           16 | 0.000162291 |   0.36995  | 1.8298   |     0.5789 |                    2 |\n",
      "| train_fashion_369b0_00006 | TERMINATED | 192.168.0.135:481602 |           64 | 0.00289137  |   0.818959 | 0.507381 |     0.8213 |                    3 |\n",
      "| train_fashion_369b0_00007 | TERMINATED | 192.168.0.135:481650 |           64 | 0.00169799  |   0.684505 | 0.770677 |     0.7151 |                    2 |\n",
      "+---------------------------+------------+----------------------+--------------+-------------+------------+----------+------------+----------------------+\n",
      "\n",
      "\n",
      "\u001B[2m\u001B[36m(train_fashion pid=481650)\u001B[0m [2,  2000] loss: 0.661\u001B[32m [repeated 2x across cluster]\u001B[0m\n",
      "== Status ==\n",
      "Current time: 2023-05-14 15:00:12 (running for 00:02:26.59)\n",
      "Using AsyncHyperBand: num_stopped=8\n",
      "Bracket: Iter 2.000: -0.6003801437320223 | Iter 1.000: -0.9023655880788329\n",
      "Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/jim/ray_results/train_fashion_2023-05-14_14-57-40\n",
      "Number of trials: 10/10 (2 RUNNING, 8 TERMINATED)\n",
      "+---------------------------+------------+----------------------+--------------+-------------+------------+----------+------------+----------------------+\n",
      "| Trial name                | status     | loc                  |   batch_size |          lr |   momentum |     loss |   accuracy |   training_iteration |\n",
      "|---------------------------+------------+----------------------+--------------+-------------+------------+----------+------------+----------------------|\n",
      "| train_fashion_369b0_00008 | RUNNING    | 192.168.0.135:481652 |           16 | 0.00102337  |   0.700704 | 0.575693 |     0.7977 |                    2 |\n",
      "| train_fashion_369b0_00009 | RUNNING    | 192.168.0.135:481650 |           16 | 0.000636541 |   0.802663 | 0.731827 |     0.7259 |                    1 |\n",
      "| train_fashion_369b0_00000 | TERMINATED | 192.168.0.135:481602 |          128 | 0.000330542 |   0.353592 | 2.20102  |     0.2912 |                    3 |\n",
      "| train_fashion_369b0_00001 | TERMINATED | 192.168.0.135:481650 |           64 | 0.00186854  |   0.843826 | 0.53785  |     0.809  |                    3 |\n",
      "| train_fashion_369b0_00002 | TERMINATED | 192.168.0.135:481652 |          128 | 0.00029119  |   0.552573 | 2.25731  |     0.2975 |                    1 |\n",
      "| train_fashion_369b0_00003 | TERMINATED | 192.168.0.135:481684 |          128 | 0.00043195  |   0.47837  | 2.24958  |     0.2619 |                    1 |\n",
      "| train_fashion_369b0_00004 | TERMINATED | 192.168.0.135:481684 |           16 | 0.00708167  |   0.769759 | 0.399538 |     0.8551 |                    3 |\n",
      "| train_fashion_369b0_00005 | TERMINATED | 192.168.0.135:481652 |           16 | 0.000162291 |   0.36995  | 1.8298   |     0.5789 |                    2 |\n",
      "| train_fashion_369b0_00006 | TERMINATED | 192.168.0.135:481602 |           64 | 0.00289137  |   0.818959 | 0.507381 |     0.8213 |                    3 |\n",
      "| train_fashion_369b0_00007 | TERMINATED | 192.168.0.135:481650 |           64 | 0.00169799  |   0.684505 | 0.770677 |     0.7151 |                    2 |\n",
      "+---------------------------+------------+----------------------+--------------+-------------+------------+----------+------------+----------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2023-05-14 15:00:17 (running for 00:02:31.59)\n",
      "Using AsyncHyperBand: num_stopped=8\n",
      "Bracket: Iter 2.000: -0.6003801437320223 | Iter 1.000: -0.9023655880788329\n",
      "Logical resource usage: 8.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/jim/ray_results/train_fashion_2023-05-14_14-57-40\n",
      "Number of trials: 10/10 (2 RUNNING, 8 TERMINATED)\n",
      "+---------------------------+------------+----------------------+--------------+-------------+------------+----------+------------+----------------------+\n",
      "| Trial name                | status     | loc                  |   batch_size |          lr |   momentum |     loss |   accuracy |   training_iteration |\n",
      "|---------------------------+------------+----------------------+--------------+-------------+------------+----------+------------+----------------------|\n",
      "| train_fashion_369b0_00008 | RUNNING    | 192.168.0.135:481652 |           16 | 0.00102337  |   0.700704 | 0.575693 |     0.7977 |                    2 |\n",
      "| train_fashion_369b0_00009 | RUNNING    | 192.168.0.135:481650 |           16 | 0.000636541 |   0.802663 | 0.731827 |     0.7259 |                    1 |\n",
      "| train_fashion_369b0_00000 | TERMINATED | 192.168.0.135:481602 |          128 | 0.000330542 |   0.353592 | 2.20102  |     0.2912 |                    3 |\n",
      "| train_fashion_369b0_00001 | TERMINATED | 192.168.0.135:481650 |           64 | 0.00186854  |   0.843826 | 0.53785  |     0.809  |                    3 |\n",
      "| train_fashion_369b0_00002 | TERMINATED | 192.168.0.135:481652 |          128 | 0.00029119  |   0.552573 | 2.25731  |     0.2975 |                    1 |\n",
      "| train_fashion_369b0_00003 | TERMINATED | 192.168.0.135:481684 |          128 | 0.00043195  |   0.47837  | 2.24958  |     0.2619 |                    1 |\n",
      "| train_fashion_369b0_00004 | TERMINATED | 192.168.0.135:481684 |           16 | 0.00708167  |   0.769759 | 0.399538 |     0.8551 |                    3 |\n",
      "| train_fashion_369b0_00005 | TERMINATED | 192.168.0.135:481652 |           16 | 0.000162291 |   0.36995  | 1.8298   |     0.5789 |                    2 |\n",
      "| train_fashion_369b0_00006 | TERMINATED | 192.168.0.135:481602 |           64 | 0.00289137  |   0.818959 | 0.507381 |     0.8213 |                    3 |\n",
      "| train_fashion_369b0_00007 | TERMINATED | 192.168.0.135:481650 |           64 | 0.00169799  |   0.684505 | 0.770677 |     0.7151 |                    2 |\n",
      "+---------------------------+------------+----------------------+--------------+-------------+------------+----------+------------+----------------------+\n",
      "\n",
      "\n",
      "\u001B[2m\u001B[36m(train_fashion pid=481650)\u001B[0m [3,  2000] loss: 0.542\u001B[32m [repeated 2x across cluster]\u001B[0m\n",
      "== Status ==\n",
      "Current time: 2023-05-14 15:00:27 (running for 00:02:40.68)\n",
      "Using AsyncHyperBand: num_stopped=9\n",
      "Bracket: Iter 2.000: -0.5909972912401911 | Iter 1.000: -0.9023655880788329\n",
      "Logical resource usage: 4.0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/jim/ray_results/train_fashion_2023-05-14_14-57-40\n",
      "Number of trials: 10/10 (1 RUNNING, 9 TERMINATED)\n",
      "+---------------------------+------------+----------------------+--------------+-------------+------------+----------+------------+----------------------+\n",
      "| Trial name                | status     | loc                  |   batch_size |          lr |   momentum |     loss |   accuracy |   training_iteration |\n",
      "|---------------------------+------------+----------------------+--------------+-------------+------------+----------+------------+----------------------|\n",
      "| train_fashion_369b0_00009 | RUNNING    | 192.168.0.135:481650 |           16 | 0.000636541 |   0.802663 | 0.581614 |     0.7967 |                    2 |\n",
      "| train_fashion_369b0_00000 | TERMINATED | 192.168.0.135:481602 |          128 | 0.000330542 |   0.353592 | 2.20102  |     0.2912 |                    3 |\n",
      "| train_fashion_369b0_00001 | TERMINATED | 192.168.0.135:481650 |           64 | 0.00186854  |   0.843826 | 0.53785  |     0.809  |                    3 |\n",
      "| train_fashion_369b0_00002 | TERMINATED | 192.168.0.135:481652 |          128 | 0.00029119  |   0.552573 | 2.25731  |     0.2975 |                    1 |\n",
      "| train_fashion_369b0_00003 | TERMINATED | 192.168.0.135:481684 |          128 | 0.00043195  |   0.47837  | 2.24958  |     0.2619 |                    1 |\n",
      "| train_fashion_369b0_00004 | TERMINATED | 192.168.0.135:481684 |           16 | 0.00708167  |   0.769759 | 0.399538 |     0.8551 |                    3 |\n",
      "| train_fashion_369b0_00005 | TERMINATED | 192.168.0.135:481652 |           16 | 0.000162291 |   0.36995  | 1.8298   |     0.5789 |                    2 |\n",
      "| train_fashion_369b0_00006 | TERMINATED | 192.168.0.135:481602 |           64 | 0.00289137  |   0.818959 | 0.507381 |     0.8213 |                    3 |\n",
      "| train_fashion_369b0_00007 | TERMINATED | 192.168.0.135:481650 |           64 | 0.00169799  |   0.684505 | 0.770677 |     0.7151 |                    2 |\n",
      "| train_fashion_369b0_00008 | TERMINATED | 192.168.0.135:481652 |           16 | 0.00102337  |   0.700704 | 0.520393 |     0.8171 |                    3 |\n",
      "+---------------------------+------------+----------------------+--------------+-------------+------------+----------+------------+----------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-14 15:00:28,142\tINFO tune.py:945 -- Total run time: 162.83 seconds (161.74 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-05-14 15:00:28 (running for 00:02:41.75)\n",
      "Using AsyncHyperBand: num_stopped=10\n",
      "Bracket: Iter 2.000: -0.5909972912401911 | Iter 1.000: -0.9023655880788329\n",
      "Logical resource usage: 0/16 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
      "Result logdir: /home/jim/ray_results/train_fashion_2023-05-14_14-57-40\n",
      "Number of trials: 10/10 (10 TERMINATED)\n",
      "+---------------------------+------------+----------------------+--------------+-------------+------------+----------+------------+----------------------+\n",
      "| Trial name                | status     | loc                  |   batch_size |          lr |   momentum |     loss |   accuracy |   training_iteration |\n",
      "|---------------------------+------------+----------------------+--------------+-------------+------------+----------+------------+----------------------|\n",
      "| train_fashion_369b0_00000 | TERMINATED | 192.168.0.135:481602 |          128 | 0.000330542 |   0.353592 | 2.20102  |     0.2912 |                    3 |\n",
      "| train_fashion_369b0_00001 | TERMINATED | 192.168.0.135:481650 |           64 | 0.00186854  |   0.843826 | 0.53785  |     0.809  |                    3 |\n",
      "| train_fashion_369b0_00002 | TERMINATED | 192.168.0.135:481652 |          128 | 0.00029119  |   0.552573 | 2.25731  |     0.2975 |                    1 |\n",
      "| train_fashion_369b0_00003 | TERMINATED | 192.168.0.135:481684 |          128 | 0.00043195  |   0.47837  | 2.24958  |     0.2619 |                    1 |\n",
      "| train_fashion_369b0_00004 | TERMINATED | 192.168.0.135:481684 |           16 | 0.00708167  |   0.769759 | 0.399538 |     0.8551 |                    3 |\n",
      "| train_fashion_369b0_00005 | TERMINATED | 192.168.0.135:481652 |           16 | 0.000162291 |   0.36995  | 1.8298   |     0.5789 |                    2 |\n",
      "| train_fashion_369b0_00006 | TERMINATED | 192.168.0.135:481602 |           64 | 0.00289137  |   0.818959 | 0.507381 |     0.8213 |                    3 |\n",
      "| train_fashion_369b0_00007 | TERMINATED | 192.168.0.135:481650 |           64 | 0.00169799  |   0.684505 | 0.770677 |     0.7151 |                    2 |\n",
      "| train_fashion_369b0_00008 | TERMINATED | 192.168.0.135:481652 |           16 | 0.00102337  |   0.700704 | 0.520393 |     0.8171 |                    3 |\n",
      "| train_fashion_369b0_00009 | TERMINATED | 192.168.0.135:481650 |           16 | 0.000636541 |   0.802663 | 0.526024 |     0.8146 |                    3 |\n",
      "+---------------------------+------------+----------------------+--------------+-------------+------------+----------+------------+----------------------+\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_samples=10  # number of experiments\n",
    "max_num_epochs=3  # reps? the \"training_iteration\" column\n",
    "gpus_per_trial=0  # I only have 1 Gpu, turning this off allows parallel?\n",
    "search_space = {\n",
    "    \"lr\": tune.loguniform(1e-4, 1e-2),\n",
    "    \"momentum\": tune.uniform(0.1, 0.9),\n",
    "    \"batch_size\": tune.choice([16, 32, 64, 128]),\n",
    "}\n",
    "scheduler = ASHAScheduler(\n",
    "    metric=\"loss\",\n",
    "    mode=\"min\",\n",
    "    max_t=max_num_epochs,\n",
    "    grace_period=1,\n",
    "    reduction_factor=2)\n",
    "reporter = CLIReporter(\n",
    "    # ``parameter_columns=[\"l1\", \"l2\", \"lr\", \"batch_size\"]``,\n",
    "    metric_columns=[\"loss\", \"accuracy\", \"training_iteration\"])\n",
    "\n",
    "tuner = tune.Tuner(\n",
    "    # train_cifar, # this default to use 1 ??\n",
    "    tune.with_resources(\n",
    "        tune.with_parameters(train_fashion),\n",
    "        resources={\"cpu\": 4, \"gpu\": gpus_per_trial}\n",
    "    ),\n",
    "    tune_config=tune.TuneConfig(\n",
    "        scheduler=scheduler,\n",
    "        num_samples=num_samples,\n",
    "    ),\n",
    "    run_config=air.RunConfig(progress_reporter=reporter),\n",
    "    param_space=search_space\n",
    ")\n",
    "result = tuner.fit()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T19:00:28.159986465Z",
     "start_time": "2023-05-14T18:57:40.144235457Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial config: {'lr': 0.007081667762167206, 'momentum': 0.7697592864340546, 'batch_size': 16}\n",
      "Best trial final validation loss: 0.39953762774467466\n",
      "Best trial final validation accuracy: 0.8551\n"
     ]
    }
   ],
   "source": [
    "best_trial = result.get_best_result(\"loss\", \"min\", \"last\")\n",
    "print(\"Best trial config: {}\".format(best_trial.config))\n",
    "print(\"Best trial final validation loss: {}\".format(\n",
    "    best_trial.metrics['loss']))\n",
    "print(\"Best trial final validation accuracy: {}\".format(\n",
    "    best_trial.metrics[\"accuracy\"]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T19:00:28.212476245Z",
     "start_time": "2023-05-14T19:00:28.161749787Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial test set accuracy: 0.8551\n"
     ]
    }
   ],
   "source": [
    "best_trained_model = NaiveDense()\n",
    "device = \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda:0\"\n",
    "    if gpus_per_trial > 1:\n",
    "        best_trained_model = nn.DataParallel(best_trained_model)\n",
    "best_trained_model.to(device)\n",
    "\n",
    "best_checkpoint_dir = best_trial.checkpoint.path\n",
    "model_state, optimizer_state = torch.load(os.path.join(\n",
    "    best_checkpoint_dir, \"checkpoint\"))\n",
    "best_trained_model.load_state_dict(model_state)\n",
    "\n",
    "test_acc = test_accuracy(best_trained_model, device)\n",
    "print(\"Best trial test set accuracy: {}\".format(test_acc))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T19:00:29.750865569Z",
     "start_time": "2023-05-14T19:00:28.202573542Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-14T19:00:29.752301161Z",
     "start_time": "2023-05-14T19:00:29.751173500Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
