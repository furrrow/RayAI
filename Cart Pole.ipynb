{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Cart Pole Example\n",
    "An old classic RL beginner problem.\n",
    "https://www.anyscale.com/blog/an-introduction-to-reinforcement-learning-with-openai-gym-rllib-and-google\n",
    "\n",
    "the intent is to see how exactly RLLib can fit into a dead simple RL problem."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import torch\n",
    "import gymnasium as gym\n",
    "import ray\n",
    "from gym.wrappers.monitoring.video_recorder import VideoRecorder\n",
    "from ray.rllib.algorithms.ppo import PPOConfig\n",
    "from ray.rllib.algorithms.dqn.dqn import DQNConfig\n",
    "from ray.tune.logger import pretty_print"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-15T05:46:32.730419026Z",
     "start_time": "2023-06-15T05:46:28.088367024Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cpu')"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    !nvidia-smi\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "device"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-15T05:46:32.745347197Z",
     "start_time": "2023-06-15T05:46:32.740227790Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# env = gym.make(\"LunarLander-v2\", render_mode=\"human\")\n",
    "env = gym.make(\"CartPole-v1\", render_mode=\"human\")\n",
    "observation, info = env.reset()\n",
    "\n",
    "for _ in range(100):\n",
    "    action = env.action_space.sample()  # agent policy that uses the observation and info\n",
    "    observation, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "    if terminated or truncated:\n",
    "        observation, info = env.reset()\n",
    "\n",
    "env.close()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-15T05:46:35.266766561Z",
     "start_time": "2023-06-15T05:46:32.748112480Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-14 22:53:32,818\tINFO algorithm.py:501 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001B[2m\u001B[36m(RolloutWorker pid=82523)\u001B[0m 2023-06-14 22:53:38,258\tWARNING env.py:159 -- Your env reset() method appears to take 'seed' or 'return_info' arguments. Note that these are not yet supported in RLlib. Seeding will take place using 'env.seed()' and the info dict will not be returned from reset.\n",
      "2023-06-14 22:53:38,350\tWARNING util.py:66 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent_timesteps_total: 4000\n",
      "counters:\n",
      "  num_agent_steps_sampled: 4000\n",
      "  num_agent_steps_trained: 4000\n",
      "  num_env_steps_sampled: 4000\n",
      "  num_env_steps_trained: 4000\n",
      "custom_metrics: {}\n",
      "date: 2023-06-14_22-54-02\n",
      "done: false\n",
      "episode_len_mean: 22.732558139534884\n",
      "episode_media: {}\n",
      "episode_reward_max: 66.0\n",
      "episode_reward_mean: 22.732558139534884\n",
      "episode_reward_min: 9.0\n",
      "episodes_this_iter: 172\n",
      "episodes_total: 172\n",
      "experiment_id: b27048a724b6493a9a831e6111018312\n",
      "hostname: furman\n",
      "info:\n",
      "  learner:\n",
      "    default_policy:\n",
      "      custom_metrics: {}\n",
      "      diff_num_grad_updates_vs_sampler_policy: 464.5\n",
      "      learner_stats:\n",
      "        allreduce_latency: 0.0\n",
      "        cur_kl_coeff: 0.20000000000000004\n",
      "        cur_lr: 5.0000000000000016e-05\n",
      "        entropy: 0.6661100400391445\n",
      "        entropy_coeff: 0.0\n",
      "        grad_gnorm: 1.5103502790133159\n",
      "        kl: 0.028344952762677365\n",
      "        policy_loss: -0.04215431610342636\n",
      "        total_loss: 8.93649986636254\n",
      "        vf_explained_var: 0.0038692155832885412\n",
      "        vf_loss: 8.972985182013563\n",
      "      model: {}\n",
      "      num_agent_steps_trained: 128.0\n",
      "      num_grad_updates_lifetime: 465.5\n",
      "  num_agent_steps_sampled: 4000\n",
      "  num_agent_steps_trained: 4000\n",
      "  num_env_steps_sampled: 4000\n",
      "  num_env_steps_trained: 4000\n",
      "iterations_since_restore: 1\n",
      "node_ip: 10.52.0.38\n",
      "num_agent_steps_sampled: 4000\n",
      "num_agent_steps_trained: 4000\n",
      "num_env_steps_sampled: 4000\n",
      "num_env_steps_sampled_this_iter: 4000\n",
      "num_env_steps_trained: 4000\n",
      "num_env_steps_trained_this_iter: 4000\n",
      "num_faulty_episodes: 0\n",
      "num_healthy_workers: 1\n",
      "num_in_flight_async_reqs: 0\n",
      "num_remote_worker_restarts: 0\n",
      "num_steps_trained_this_iter: 4000\n",
      "perf:\n",
      "  cpu_util_percent: 17.308571428571426\n",
      "  ram_util_percent: 62.568571428571445\n",
      "pid: 81262\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0956618645822248\n",
      "  mean_env_render_ms: 0.0\n",
      "  mean_env_wait_ms: 0.1105321284920774\n",
      "  mean_inference_ms: 1.715655566394046\n",
      "  mean_raw_obs_processing_ms: 0.5608248549740008\n",
      "sampler_results:\n",
      "  custom_metrics: {}\n",
      "  episode_len_mean: 22.732558139534884\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 66.0\n",
      "  episode_reward_mean: 22.732558139534884\n",
      "  episode_reward_min: 9.0\n",
      "  episodes_this_iter: 172\n",
      "  hist_stats:\n",
      "    episode_lengths: [18, 15, 26, 22, 11, 17, 12, 18, 36, 38, 24, 12, 46, 18, 22,\n",
      "      10, 35, 11, 16, 15, 25, 25, 19, 27, 28, 20, 19, 15, 33, 18, 25, 24, 22, 11,\n",
      "      44, 13, 12, 11, 15, 13, 20, 15, 14, 19, 9, 12, 35, 26, 28, 12, 15, 14, 25, 32,\n",
      "      14, 12, 12, 10, 19, 23, 23, 27, 30, 28, 30, 20, 17, 23, 44, 11, 21, 66, 31,\n",
      "      17, 48, 26, 30, 46, 25, 18, 28, 62, 10, 11, 17, 19, 21, 53, 29, 18, 12, 10,\n",
      "      13, 19, 12, 29, 30, 9, 11, 47, 19, 28, 24, 41, 53, 10, 13, 21, 28, 11, 16, 9,\n",
      "      18, 18, 19, 25, 20, 12, 21, 17, 18, 32, 17, 10, 40, 15, 11, 21, 22, 9, 12, 18,\n",
      "      52, 51, 17, 10, 10, 34, 20, 33, 21, 34, 14, 18, 26, 17, 29, 16, 11, 25, 25,\n",
      "      43, 35, 49, 19, 29, 11, 45, 9, 13, 59, 14, 17, 30, 36, 18, 31, 22, 10, 10, 20,\n",
      "      31]\n",
      "    episode_reward: [18.0, 15.0, 26.0, 22.0, 11.0, 17.0, 12.0, 18.0, 36.0, 38.0, 24.0,\n",
      "      12.0, 46.0, 18.0, 22.0, 10.0, 35.0, 11.0, 16.0, 15.0, 25.0, 25.0, 19.0, 27.0,\n",
      "      28.0, 20.0, 19.0, 15.0, 33.0, 18.0, 25.0, 24.0, 22.0, 11.0, 44.0, 13.0, 12.0,\n",
      "      11.0, 15.0, 13.0, 20.0, 15.0, 14.0, 19.0, 9.0, 12.0, 35.0, 26.0, 28.0, 12.0,\n",
      "      15.0, 14.0, 25.0, 32.0, 14.0, 12.0, 12.0, 10.0, 19.0, 23.0, 23.0, 27.0, 30.0,\n",
      "      28.0, 30.0, 20.0, 17.0, 23.0, 44.0, 11.0, 21.0, 66.0, 31.0, 17.0, 48.0, 26.0,\n",
      "      30.0, 46.0, 25.0, 18.0, 28.0, 62.0, 10.0, 11.0, 17.0, 19.0, 21.0, 53.0, 29.0,\n",
      "      18.0, 12.0, 10.0, 13.0, 19.0, 12.0, 29.0, 30.0, 9.0, 11.0, 47.0, 19.0, 28.0,\n",
      "      24.0, 41.0, 53.0, 10.0, 13.0, 21.0, 28.0, 11.0, 16.0, 9.0, 18.0, 18.0, 19.0,\n",
      "      25.0, 20.0, 12.0, 21.0, 17.0, 18.0, 32.0, 17.0, 10.0, 40.0, 15.0, 11.0, 21.0,\n",
      "      22.0, 9.0, 12.0, 18.0, 52.0, 51.0, 17.0, 10.0, 10.0, 34.0, 20.0, 33.0, 21.0,\n",
      "      34.0, 14.0, 18.0, 26.0, 17.0, 29.0, 16.0, 11.0, 25.0, 25.0, 43.0, 35.0, 49.0,\n",
      "      19.0, 29.0, 11.0, 45.0, 9.0, 13.0, 59.0, 14.0, 17.0, 30.0, 36.0, 18.0, 31.0,\n",
      "      22.0, 10.0, 10.0, 20.0, 31.0]\n",
      "  num_faulty_episodes: 0\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0956618645822248\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.1105321284920774\n",
      "    mean_inference_ms: 1.715655566394046\n",
      "    mean_raw_obs_processing_ms: 0.5608248549740008\n",
      "time_since_restore: 23.93906283378601\n",
      "time_this_iter_s: 23.93906283378601\n",
      "time_total_s: 23.93906283378601\n",
      "timers:\n",
      "  learn_throughput: 287.105\n",
      "  learn_time_ms: 13932.164\n",
      "  load_throughput: 5023118.563\n",
      "  load_time_ms: 0.796\n",
      "  synch_weights_time_ms: 2.359\n",
      "  training_iteration_time_ms: 23932.08\n",
      "timestamp: 1686797642\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 4000\n",
      "training_iteration: 1\n",
      "trial_id: default\n",
      "warmup_time: 5.537008285522461\n",
      "\n",
      "Checkpoint saved in directory ./checkpoints/checkpoint_000001\n"
     ]
    }
   ],
   "source": [
    "from ray.rllib.algorithms.ppo import PPOConfig\n",
    "from ray.tune.logger import pretty_print\n",
    "\n",
    "\n",
    "algo = (\n",
    "    PPOConfig()\n",
    "    .framework('torch')\n",
    "    .rollouts(num_rollout_workers=1)\n",
    "    .resources(num_gpus=0)\n",
    "    .environment(env=\"CartPole-v1\")\n",
    "    .build()\n",
    ")\n",
    "\n",
    "for i in range(1):\n",
    "    result = algo.train()\n",
    "    print(pretty_print(result))\n",
    "\n",
    "    if i % 1 == 0:\n",
    "        checkpoint_dir = algo.save(checkpoint_dir=\"./checkpoints\")\n",
    "        print(f\"Checkpoint saved in directory {checkpoint_dir}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-15T02:54:02.404122572Z",
     "start_time": "2023-06-15T02:53:32.787664954Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-15 02:06:06,123\tINFO worker.py:1529 -- Started a local Ray instance. View the dashboard at \u001B[1m\u001B[32m127.0.0.1:8265 \u001B[39m\u001B[22m\n"
     ]
    },
    {
     "ename": "TuneError",
     "evalue": "The Ray Tune run failed. Please inspect the previous error messages for a cause. After fixing the issue, you can restart the run from scratch or continue this run. To continue this run, you can use `tuner = Tuner.restore(\"/home/furman/ray_results/PPO\")`.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "File \u001B[0;32m~/mambaforge/envs/ray/lib/python3.10/site-packages/ray/tune/tuner.py:272\u001B[0m, in \u001B[0;36mTuner.fit\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    271\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 272\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_local_tuner\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    273\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[0;32m~/mambaforge/envs/ray/lib/python3.10/site-packages/ray/tune/impl/tuner_internal.py:420\u001B[0m, in \u001B[0;36mTunerInternal.fit\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    419\u001B[0m     param_space \u001B[38;5;241m=\u001B[39m copy\u001B[38;5;241m.\u001B[39mdeepcopy(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_param_space)\n\u001B[0;32m--> 420\u001B[0m     analysis \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit_internal\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrainable\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparam_space\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    421\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m~/mambaforge/envs/ray/lib/python3.10/site-packages/ray/tune/impl/tuner_internal.py:520\u001B[0m, in \u001B[0;36mTunerInternal._fit_internal\u001B[0;34m(self, trainable, param_space)\u001B[0m\n\u001B[1;32m    518\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Fitting for a fresh Tuner.\"\"\"\u001B[39;00m\n\u001B[1;32m    519\u001B[0m args \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m--> 520\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_tune_run_arguments\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrainable\u001B[49m\u001B[43m)\u001B[49m,\n\u001B[1;32m    521\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mdict\u001B[39m(\n\u001B[1;32m    522\u001B[0m         run_or_experiment\u001B[38;5;241m=\u001B[39mtrainable,\n\u001B[1;32m    523\u001B[0m         config\u001B[38;5;241m=\u001B[39m{\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparam_space},\n\u001B[1;32m    524\u001B[0m         num_samples\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tune_config\u001B[38;5;241m.\u001B[39mnum_samples,\n\u001B[1;32m    525\u001B[0m         search_alg\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tune_config\u001B[38;5;241m.\u001B[39msearch_alg,\n\u001B[1;32m    526\u001B[0m         scheduler\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tune_config\u001B[38;5;241m.\u001B[39mscheduler,\n\u001B[1;32m    527\u001B[0m         name\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_run_config\u001B[38;5;241m.\u001B[39mname,\n\u001B[1;32m    528\u001B[0m         log_to_file\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_run_config\u001B[38;5;241m.\u001B[39mlog_to_file,\n\u001B[1;32m    529\u001B[0m     ),\n\u001B[1;32m    530\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tuner_kwargs,\n\u001B[1;32m    531\u001B[0m }\n\u001B[1;32m    532\u001B[0m analysis \u001B[38;5;241m=\u001B[39m run(\n\u001B[1;32m    533\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39margs,\n\u001B[1;32m    534\u001B[0m )\n",
      "File \u001B[0;32m~/mambaforge/envs/ray/lib/python3.10/site-packages/ray/tune/impl/tuner_internal.py:483\u001B[0m, in \u001B[0;36mTunerInternal._get_tune_run_arguments\u001B[0;34m(self, trainable)\u001B[0m\n\u001B[1;32m    480\u001B[0m     \u001B[38;5;66;03m# If this is a user-defined trainable, just keep the value\u001B[39;00m\n\u001B[1;32m    481\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    482\u001B[0m     \u001B[38;5;66;03m# Set default to False for function trainables and True for everything else\u001B[39;00m\n\u001B[0;32m--> 483\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[43mis_function_trainable\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrainable\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[1;32m    484\u001B[0m         checkpoint_at_end \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[0;32m~/mambaforge/envs/ray/lib/python3.10/site-packages/ray/tune/registry.py:64\u001B[0m, in \u001B[0;36mis_function_trainable\u001B[0;34m(trainable)\u001B[0m\n\u001B[1;32m     63\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(trainable, \u001B[38;5;28mstr\u001B[39m):\n\u001B[0;32m---> 64\u001B[0m     trainable \u001B[38;5;241m=\u001B[39m \u001B[43mget_trainable_cls\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrainable\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     66\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(trainable, \u001B[38;5;28mtype\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m (\n\u001B[1;32m     67\u001B[0m     \u001B[38;5;28misinstance\u001B[39m(trainable, FunctionType)\n\u001B[1;32m     68\u001B[0m     \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(trainable, partial)\n\u001B[1;32m     69\u001B[0m     \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mcallable\u001B[39m(trainable)\n\u001B[1;32m     70\u001B[0m )\n",
      "File \u001B[0;32m~/mambaforge/envs/ray/lib/python3.10/site-packages/ray/tune/registry.py:45\u001B[0m, in \u001B[0;36mget_trainable_cls\u001B[0;34m(trainable_name)\u001B[0m\n\u001B[1;32m     43\u001B[0m \u001B[38;5;129m@DeveloperAPI\u001B[39m\n\u001B[1;32m     44\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_trainable_cls\u001B[39m(trainable_name):\n\u001B[0;32m---> 45\u001B[0m     \u001B[43mvalidate_trainable\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrainable_name\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     46\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _global_registry\u001B[38;5;241m.\u001B[39mget(TRAINABLE_CLASS, trainable_name)\n",
      "File \u001B[0;32m~/mambaforge/envs/ray/lib/python3.10/site-packages/ray/tune/registry.py:55\u001B[0m, in \u001B[0;36mvalidate_trainable\u001B[0;34m(trainable_name)\u001B[0m\n\u001B[1;32m     53\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mray\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mrllib\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _register_all\n\u001B[0;32m---> 55\u001B[0m \u001B[43m_register_all\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     56\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m _has_trainable(trainable_name):\n",
      "File \u001B[0;32m~/mambaforge/envs/ray/lib/python3.10/site-packages/ray/rllib/__init__.py:39\u001B[0m, in \u001B[0;36m_register_all\u001B[0;34m()\u001B[0m\n\u001B[1;32m     36\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m key, get_trainable_class_and_config \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mlist\u001B[39m(ALGORITHMS\u001B[38;5;241m.\u001B[39mitems()) \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mlist\u001B[39m(\n\u001B[1;32m     37\u001B[0m     CONTRIBUTED_ALGORITHMS\u001B[38;5;241m.\u001B[39mitems()\n\u001B[1;32m     38\u001B[0m ):\n\u001B[0;32m---> 39\u001B[0m     register_trainable(key, \u001B[43mget_trainable_class_and_config\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;241m0\u001B[39m])\n\u001B[1;32m     41\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m key \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__fake\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__sigmoid_fake_data\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__parameter_tuning\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n",
      "File \u001B[0;32m~/mambaforge/envs/ray/lib/python3.10/site-packages/ray/rllib/algorithms/registry.py:65\u001B[0m, in \u001B[0;36m_import_bandit_lints\u001B[0;34m()\u001B[0m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_import_bandit_lints\u001B[39m():\n\u001B[0;32m---> 65\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mray\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mrllib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01malgorithms\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbandit\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbandit\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m BanditLinTS\n\u001B[1;32m     67\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m BanditLinTS, BanditLinTS\u001B[38;5;241m.\u001B[39mget_default_config()\n",
      "File \u001B[0;32m~/mambaforge/envs/ray/lib/python3.10/site-packages/ray/rllib/algorithms/bandit/__init__.py:1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mray\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mrllib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01malgorithms\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbandit\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbandit\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m      2\u001B[0m     BanditLinTS,\n\u001B[1;32m      3\u001B[0m     BanditLinUCB,\n\u001B[1;32m      4\u001B[0m     BanditLinTSConfig,\n\u001B[1;32m      5\u001B[0m     BanditLinUCBConfig,\n\u001B[1;32m      6\u001B[0m )\n\u001B[1;32m      8\u001B[0m __all__ \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m      9\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBanditLinTS\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     10\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBanditLinUCB\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     11\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBanditLinTSConfig\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     12\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBanditLinUCBConfig\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     13\u001B[0m ]\n",
      "File \u001B[0;32m~/mambaforge/envs/ray/lib/python3.10/site-packages/ray/rllib/algorithms/bandit/bandit.py:6\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mray\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mrllib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01malgorithms\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01malgorithm_config\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m AlgorithmConfig\n\u001B[0;32m----> 6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mray\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mrllib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01malgorithms\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbandit\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbandit_tf_policy\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m BanditTFPolicy\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mray\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mrllib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01malgorithms\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbandit\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbandit_torch_policy\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m BanditTorchPolicy\n",
      "File \u001B[0;32m~/mambaforge/envs/ray/lib/python3.10/site-packages/ray/rllib/algorithms/bandit/bandit_tf_policy.py:8\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mray\u001B[39;00m\n\u001B[0;32m----> 8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mray\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mrllib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01malgorithms\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbandit\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbandit_tf_model\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m      9\u001B[0m     DiscreteLinearModelThompsonSampling,\n\u001B[1;32m     10\u001B[0m     DiscreteLinearModelUCB,\n\u001B[1;32m     11\u001B[0m     DiscreteLinearModel,\n\u001B[1;32m     12\u001B[0m     ParametricLinearModelThompsonSampling,\n\u001B[1;32m     13\u001B[0m     ParametricLinearModelUCB,\n\u001B[1;32m     14\u001B[0m )\n\u001B[1;32m     15\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mray\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mrllib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodels\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcatalog\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ModelCatalog\n",
      "File \u001B[0;32m~/mambaforge/envs/ray/lib/python3.10/site-packages/ray/rllib/algorithms/bandit/bandit_tf_model.py:2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mgym\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtensorflow_probability\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mtfp\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mray\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mrllib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodels\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodelv2\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ModelV2\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'tensorflow_probability'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mTuneError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[19], line 17\u001B[0m\n\u001B[1;32m      7\u001B[0m config \u001B[38;5;241m=\u001B[39m PPOConfig()\u001B[38;5;241m.\u001B[39mframework(framework\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtorch\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m.\u001B[39mtraining(lr\u001B[38;5;241m=\u001B[39mtune\u001B[38;5;241m.\u001B[39mgrid_search([\u001B[38;5;241m0.01\u001B[39m, \u001B[38;5;241m0.001\u001B[39m, \u001B[38;5;241m0.0001\u001B[39m]))\n\u001B[1;32m      9\u001B[0m tuner \u001B[38;5;241m=\u001B[39m tune\u001B[38;5;241m.\u001B[39mTuner(\n\u001B[1;32m     10\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPPO\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     11\u001B[0m     run_config\u001B[38;5;241m=\u001B[39mair\u001B[38;5;241m.\u001B[39mRunConfig(\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     14\u001B[0m     param_space\u001B[38;5;241m=\u001B[39mconfig,\n\u001B[1;32m     15\u001B[0m )\n\u001B[0;32m---> 17\u001B[0m \u001B[43mtuner\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/mambaforge/envs/ray/lib/python3.10/site-packages/ray/tune/tuner.py:274\u001B[0m, in \u001B[0;36mTuner.fit\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    272\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_local_tuner\u001B[38;5;241m.\u001B[39mfit()\n\u001B[1;32m    273\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m--> 274\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m TuneError(\n\u001B[1;32m    275\u001B[0m             _TUNER_FAILED_MSG\u001B[38;5;241m.\u001B[39mformat(\n\u001B[1;32m    276\u001B[0m                 path\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_local_tuner\u001B[38;5;241m.\u001B[39mget_experiment_checkpoint_dir()\n\u001B[1;32m    277\u001B[0m             )\n\u001B[1;32m    278\u001B[0m         ) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n\u001B[1;32m    279\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    280\u001B[0m     experiment_checkpoint_dir \u001B[38;5;241m=\u001B[39m ray\u001B[38;5;241m.\u001B[39mget(\n\u001B[1;32m    281\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_remote_tuner\u001B[38;5;241m.\u001B[39mget_experiment_checkpoint_dir\u001B[38;5;241m.\u001B[39mremote()\n\u001B[1;32m    282\u001B[0m     )\n",
      "\u001B[0;31mTuneError\u001B[0m: The Ray Tune run failed. Please inspect the previous error messages for a cause. After fixing the issue, you can restart the run from scratch or continue this run. To continue this run, you can use `tuner = Tuner.restore(\"/home/furman/ray_results/PPO\")`."
     ]
    }
   ],
   "source": [
    "import ray\n",
    "from ray import air, tune\n",
    "ray.shutdown()\n",
    "ray.init()\n",
    "\n",
    "## NOTE: Could not solve the tensorflow_probability error, suspect I do not know how to properly set config to torch.\n",
    "## Possible that I am not able to use tuner.fit() at all...\n",
    "config = PPOConfig().framework(framework=\"torch\").training(lr=tune.grid_search([0.01, 0.001, 0.0001]))\n",
    "\n",
    "tuner = tune.Tuner(\n",
    "    \"PPO\",\n",
    "    run_config=air.RunConfig(\n",
    "        stop={\"episode_reward_mean\": 150},\n",
    "    ),\n",
    "    param_space=config,\n",
    ")\n",
    "\n",
    "tuner.fit()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-15T06:06:14.241249523Z",
     "start_time": "2023-06-15T06:06:01.706123572Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-15 02:08:12,626\tINFO worker.py:1529 -- Started a local Ray instance. View the dashboard at \u001B[1m\u001B[32m127.0.0.1:8265 \u001B[39m\u001B[22m\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow_probability'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[20], line 19\u001B[0m\n\u001B[1;32m     12\u001B[0m ray\u001B[38;5;241m.\u001B[39minit(\n\u001B[1;32m     13\u001B[0m     num_cpus\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m,\n\u001B[1;32m     14\u001B[0m     include_dashboard\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m     15\u001B[0m     ignore_reinit_error\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m     16\u001B[0m     log_to_driver\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m     17\u001B[0m )\n\u001B[1;32m     18\u001B[0m \u001B[38;5;66;03m# execute training\u001B[39;00m\n\u001B[0;32m---> 19\u001B[0m analysis \u001B[38;5;241m=\u001B[39m \u001B[43mray\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtune\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     20\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mPPO\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     21\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlocal_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m./checkpoints\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     22\u001B[0m \u001B[43m    \u001B[49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     23\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstop\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     24\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcheckpoint_at_end\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m     25\u001B[0m \u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/mambaforge/envs/ray/lib/python3.10/site-packages/ray/tune/tune.py:484\u001B[0m, in \u001B[0;36mrun\u001B[0;34m(run_or_experiment, name, metric, mode, stop, time_budget_s, config, resources_per_trial, num_samples, local_dir, search_alg, scheduler, keep_checkpoints_num, checkpoint_score_attr, checkpoint_freq, checkpoint_at_end, verbose, progress_reporter, log_to_file, trial_name_creator, trial_dirname_creator, chdir_to_trial_dir, sync_config, export_formats, max_failures, fail_fast, restore, server_port, resume, reuse_actors, trial_executor, raise_on_failed_trial, callbacks, max_concurrent_trials, _experiment_checkpoint_dir, _remote, _remote_string_queue)\u001B[0m\n\u001B[1;32m    476\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m reuse_actors \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    477\u001B[0m     trainable \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    478\u001B[0m         run_or_experiment\u001B[38;5;241m.\u001B[39mrun_identifier\n\u001B[1;32m    479\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(run_or_experiment, Experiment)\n\u001B[1;32m    480\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m run_or_experiment\n\u001B[1;32m    481\u001B[0m     )\n\u001B[1;32m    482\u001B[0m     reuse_actors \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    483\u001B[0m         \u001B[38;5;66;03m# Only default to True for function trainables that meet certain conditions\u001B[39;00m\n\u001B[0;32m--> 484\u001B[0m         \u001B[43mis_function_trainable\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrainable\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    485\u001B[0m         \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\n\u001B[1;32m    486\u001B[0m             \u001B[38;5;66;03m# Changing resources requires restarting actors\u001B[39;00m\n\u001B[1;32m    487\u001B[0m             scheduler\n\u001B[1;32m    488\u001B[0m             \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(scheduler, ResourceChangingScheduler)\n\u001B[1;32m    489\u001B[0m         )\n\u001B[1;32m    490\u001B[0m         \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\n\u001B[1;32m    491\u001B[0m             \u001B[38;5;66;03m# If GPUs are requested we could run into problems with device memory\u001B[39;00m\n\u001B[1;32m    492\u001B[0m             _check_gpus_in_resources(resources_per_trial)\n\u001B[1;32m    493\u001B[0m         )\n\u001B[1;32m    494\u001B[0m         \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\n\u001B[1;32m    495\u001B[0m             \u001B[38;5;66;03m# If the resource request is overridden, we don't know if GPUs\u001B[39;00m\n\u001B[1;32m    496\u001B[0m             \u001B[38;5;66;03m# will be requested, yet, so default to False\u001B[39;00m\n\u001B[1;32m    497\u001B[0m             _check_default_resources_override(trainable)\n\u001B[1;32m    498\u001B[0m         )\n\u001B[1;32m    499\u001B[0m     )\n\u001B[1;32m    501\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m    502\u001B[0m     \u001B[38;5;28misinstance\u001B[39m(scheduler, (PopulationBasedTraining, PopulationBasedTrainingReplay))\n\u001B[1;32m    503\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m reuse_actors\n\u001B[1;32m    504\u001B[0m ):\n\u001B[1;32m    505\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[1;32m    506\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mConsider boosting PBT performance by enabling `reuse_actors` as \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    507\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwell as implementing `reset_config` for Trainable.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    508\u001B[0m     )\n",
      "File \u001B[0;32m~/mambaforge/envs/ray/lib/python3.10/site-packages/ray/tune/registry.py:64\u001B[0m, in \u001B[0;36mis_function_trainable\u001B[0;34m(trainable)\u001B[0m\n\u001B[1;32m     62\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Check if a given trainable is a function trainable.\"\"\"\u001B[39;00m\n\u001B[1;32m     63\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(trainable, \u001B[38;5;28mstr\u001B[39m):\n\u001B[0;32m---> 64\u001B[0m     trainable \u001B[38;5;241m=\u001B[39m \u001B[43mget_trainable_cls\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrainable\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     66\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(trainable, \u001B[38;5;28mtype\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m (\n\u001B[1;32m     67\u001B[0m     \u001B[38;5;28misinstance\u001B[39m(trainable, FunctionType)\n\u001B[1;32m     68\u001B[0m     \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(trainable, partial)\n\u001B[1;32m     69\u001B[0m     \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mcallable\u001B[39m(trainable)\n\u001B[1;32m     70\u001B[0m )\n",
      "File \u001B[0;32m~/mambaforge/envs/ray/lib/python3.10/site-packages/ray/tune/registry.py:45\u001B[0m, in \u001B[0;36mget_trainable_cls\u001B[0;34m(trainable_name)\u001B[0m\n\u001B[1;32m     43\u001B[0m \u001B[38;5;129m@DeveloperAPI\u001B[39m\n\u001B[1;32m     44\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_trainable_cls\u001B[39m(trainable_name):\n\u001B[0;32m---> 45\u001B[0m     \u001B[43mvalidate_trainable\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrainable_name\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     46\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _global_registry\u001B[38;5;241m.\u001B[39mget(TRAINABLE_CLASS, trainable_name)\n",
      "File \u001B[0;32m~/mambaforge/envs/ray/lib/python3.10/site-packages/ray/tune/registry.py:55\u001B[0m, in \u001B[0;36mvalidate_trainable\u001B[0;34m(trainable_name)\u001B[0m\n\u001B[1;32m     51\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m _has_trainable(trainable_name):\n\u001B[1;32m     52\u001B[0m     \u001B[38;5;66;03m# Make sure everything rllib-related is registered.\u001B[39;00m\n\u001B[1;32m     53\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mray\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mrllib\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _register_all\n\u001B[0;32m---> 55\u001B[0m     \u001B[43m_register_all\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     56\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m _has_trainable(trainable_name):\n\u001B[1;32m     57\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m TuneError(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnknown trainable: \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m trainable_name)\n",
      "File \u001B[0;32m~/mambaforge/envs/ray/lib/python3.10/site-packages/ray/rllib/__init__.py:39\u001B[0m, in \u001B[0;36m_register_all\u001B[0;34m()\u001B[0m\n\u001B[1;32m     34\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mray\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mrllib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcontrib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mregistry\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m CONTRIBUTED_ALGORITHMS\n\u001B[1;32m     36\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m key, get_trainable_class_and_config \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mlist\u001B[39m(ALGORITHMS\u001B[38;5;241m.\u001B[39mitems()) \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mlist\u001B[39m(\n\u001B[1;32m     37\u001B[0m     CONTRIBUTED_ALGORITHMS\u001B[38;5;241m.\u001B[39mitems()\n\u001B[1;32m     38\u001B[0m ):\n\u001B[0;32m---> 39\u001B[0m     register_trainable(key, \u001B[43mget_trainable_class_and_config\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;241m0\u001B[39m])\n\u001B[1;32m     41\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m key \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__fake\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__sigmoid_fake_data\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__parameter_tuning\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n\u001B[1;32m     42\u001B[0m     register_trainable(key, _get_algorithm_class(key))\n",
      "File \u001B[0;32m~/mambaforge/envs/ray/lib/python3.10/site-packages/ray/rllib/algorithms/registry.py:65\u001B[0m, in \u001B[0;36m_import_bandit_lints\u001B[0;34m()\u001B[0m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_import_bandit_lints\u001B[39m():\n\u001B[0;32m---> 65\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mray\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mrllib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01malgorithms\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbandit\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbandit\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m BanditLinTS\n\u001B[1;32m     67\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m BanditLinTS, BanditLinTS\u001B[38;5;241m.\u001B[39mget_default_config()\n",
      "File \u001B[0;32m~/mambaforge/envs/ray/lib/python3.10/site-packages/ray/rllib/algorithms/bandit/__init__.py:1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mray\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mrllib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01malgorithms\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbandit\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbandit\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m      2\u001B[0m     BanditLinTS,\n\u001B[1;32m      3\u001B[0m     BanditLinUCB,\n\u001B[1;32m      4\u001B[0m     BanditLinTSConfig,\n\u001B[1;32m      5\u001B[0m     BanditLinUCBConfig,\n\u001B[1;32m      6\u001B[0m )\n\u001B[1;32m      8\u001B[0m __all__ \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m      9\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBanditLinTS\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     10\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBanditLinUCB\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     11\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBanditLinTSConfig\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     12\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBanditLinUCBConfig\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     13\u001B[0m ]\n",
      "File \u001B[0;32m~/mambaforge/envs/ray/lib/python3.10/site-packages/ray/rllib/algorithms/bandit/bandit.py:6\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mray\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mrllib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01malgorithms\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01malgorithm\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Algorithm\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mray\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mrllib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01malgorithms\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01malgorithm_config\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m AlgorithmConfig\n\u001B[0;32m----> 6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mray\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mrllib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01malgorithms\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbandit\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbandit_tf_policy\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m BanditTFPolicy\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mray\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mrllib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01malgorithms\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbandit\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbandit_torch_policy\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m BanditTorchPolicy\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mray\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mrllib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpolicy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpolicy\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Policy\n",
      "File \u001B[0;32m~/mambaforge/envs/ray/lib/python3.10/site-packages/ray/rllib/algorithms/bandit/bandit_tf_policy.py:8\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mgym\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m spaces\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mray\u001B[39;00m\n\u001B[0;32m----> 8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mray\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mrllib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01malgorithms\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbandit\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbandit_tf_model\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m      9\u001B[0m     DiscreteLinearModelThompsonSampling,\n\u001B[1;32m     10\u001B[0m     DiscreteLinearModelUCB,\n\u001B[1;32m     11\u001B[0m     DiscreteLinearModel,\n\u001B[1;32m     12\u001B[0m     ParametricLinearModelThompsonSampling,\n\u001B[1;32m     13\u001B[0m     ParametricLinearModelUCB,\n\u001B[1;32m     14\u001B[0m )\n\u001B[1;32m     15\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mray\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mrllib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodels\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcatalog\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ModelCatalog\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mray\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mrllib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodels\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodelv2\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m restore_original_dimensions\n",
      "File \u001B[0;32m~/mambaforge/envs/ray/lib/python3.10/site-packages/ray/rllib/algorithms/bandit/bandit_tf_model.py:2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mgym\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtensorflow_probability\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mtfp\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mray\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mrllib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodels\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodelv2\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ModelV2\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mray\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mrllib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodels\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtf\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtf_modelv2\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m TFModelV2\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'tensorflow_probability'"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    \"env\": \"CartPole-v1\",\n",
    "    # Change the following line to `“framework”: “tf”` to use tensorflow\n",
    "    \"framework\": \"torch\",\n",
    "    \"model\": {\n",
    "        \"fcnet_hiddens\": [32],\n",
    "        \"fcnet_activation\": \"linear\",\n",
    "    },\n",
    "}\n",
    "stop = {\"episode_reward_mean\": 295}\n",
    "ray.shutdown()\n",
    "ray.init(\n",
    "    num_cpus=3,\n",
    "    include_dashboard=False,\n",
    "    ignore_reinit_error=True,\n",
    "    log_to_driver=False,\n",
    ")\n",
    "# execute training\n",
    "analysis = ray.tune.run(\n",
    "    \"PPO\",\n",
    "    local_dir=\"./checkpoints\",\n",
    "    config=config,\n",
    "    stop=stop,\n",
    "    checkpoint_at_end=True,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-15T06:08:15.113120923Z",
     "start_time": "2023-06-15T06:08:07.823324847Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-14 22:47:19,622\tINFO worker.py:1529 -- Started a local Ray instance. View the dashboard at \u001B[1m\u001B[32m127.0.0.1:8265 \u001B[39m\u001B[22m\n"
     ]
    },
    {
     "ename": "TuneError",
     "evalue": "The Ray Tune run failed. Please inspect the previous error messages for a cause. After fixing the issue, you can restart the run from scratch or continue this run. To continue this run, you can use `tuner = Tuner.restore(\"/home/furman/ray_results/PPO\")`.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "File \u001B[0;32m~/mambaforge/envs/ray/lib/python3.10/site-packages/ray/tune/tuner.py:272\u001B[0m, in \u001B[0;36mTuner.fit\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    271\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 272\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_local_tuner\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    273\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[0;32m~/mambaforge/envs/ray/lib/python3.10/site-packages/ray/tune/impl/tuner_internal.py:420\u001B[0m, in \u001B[0;36mTunerInternal.fit\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    419\u001B[0m     param_space \u001B[38;5;241m=\u001B[39m copy\u001B[38;5;241m.\u001B[39mdeepcopy(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_param_space)\n\u001B[0;32m--> 420\u001B[0m     analysis \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit_internal\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrainable\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparam_space\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    421\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m~/mambaforge/envs/ray/lib/python3.10/site-packages/ray/tune/impl/tuner_internal.py:532\u001B[0m, in \u001B[0;36mTunerInternal._fit_internal\u001B[0;34m(self, trainable, param_space)\u001B[0m\n\u001B[1;32m    519\u001B[0m args \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m    520\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_tune_run_arguments(trainable),\n\u001B[1;32m    521\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mdict\u001B[39m(\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    530\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tuner_kwargs,\n\u001B[1;32m    531\u001B[0m }\n\u001B[0;32m--> 532\u001B[0m analysis \u001B[38;5;241m=\u001B[39m \u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    533\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    534\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    535\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclear_remote_string_queue()\n",
      "File \u001B[0;32m~/mambaforge/envs/ray/lib/python3.10/site-packages/ray/tune/tune.py:484\u001B[0m, in \u001B[0;36mrun\u001B[0;34m(run_or_experiment, name, metric, mode, stop, time_budget_s, config, resources_per_trial, num_samples, local_dir, search_alg, scheduler, keep_checkpoints_num, checkpoint_score_attr, checkpoint_freq, checkpoint_at_end, verbose, progress_reporter, log_to_file, trial_name_creator, trial_dirname_creator, chdir_to_trial_dir, sync_config, export_formats, max_failures, fail_fast, restore, server_port, resume, reuse_actors, trial_executor, raise_on_failed_trial, callbacks, max_concurrent_trials, _experiment_checkpoint_dir, _remote, _remote_string_queue)\u001B[0m\n\u001B[1;32m    477\u001B[0m     trainable \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    478\u001B[0m         run_or_experiment\u001B[38;5;241m.\u001B[39mrun_identifier\n\u001B[1;32m    479\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(run_or_experiment, Experiment)\n\u001B[1;32m    480\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m run_or_experiment\n\u001B[1;32m    481\u001B[0m     )\n\u001B[1;32m    482\u001B[0m     reuse_actors \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    483\u001B[0m         \u001B[38;5;66;03m# Only default to True for function trainables that meet certain conditions\u001B[39;00m\n\u001B[0;32m--> 484\u001B[0m         \u001B[43mis_function_trainable\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrainable\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    485\u001B[0m         \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\n\u001B[1;32m    486\u001B[0m             \u001B[38;5;66;03m# Changing resources requires restarting actors\u001B[39;00m\n\u001B[1;32m    487\u001B[0m             scheduler\n\u001B[1;32m    488\u001B[0m             \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(scheduler, ResourceChangingScheduler)\n\u001B[1;32m    489\u001B[0m         )\n\u001B[1;32m    490\u001B[0m         \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\n\u001B[1;32m    491\u001B[0m             \u001B[38;5;66;03m# If GPUs are requested we could run into problems with device memory\u001B[39;00m\n\u001B[1;32m    492\u001B[0m             _check_gpus_in_resources(resources_per_trial)\n\u001B[1;32m    493\u001B[0m         )\n\u001B[1;32m    494\u001B[0m         \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\n\u001B[1;32m    495\u001B[0m             \u001B[38;5;66;03m# If the resource request is overridden, we don't know if GPUs\u001B[39;00m\n\u001B[1;32m    496\u001B[0m             \u001B[38;5;66;03m# will be requested, yet, so default to False\u001B[39;00m\n\u001B[1;32m    497\u001B[0m             _check_default_resources_override(trainable)\n\u001B[1;32m    498\u001B[0m         )\n\u001B[1;32m    499\u001B[0m     )\n\u001B[1;32m    501\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m    502\u001B[0m     \u001B[38;5;28misinstance\u001B[39m(scheduler, (PopulationBasedTraining, PopulationBasedTrainingReplay))\n\u001B[1;32m    503\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m reuse_actors\n\u001B[1;32m    504\u001B[0m ):\n",
      "File \u001B[0;32m~/mambaforge/envs/ray/lib/python3.10/site-packages/ray/tune/registry.py:64\u001B[0m, in \u001B[0;36mis_function_trainable\u001B[0;34m(trainable)\u001B[0m\n\u001B[1;32m     63\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(trainable, \u001B[38;5;28mstr\u001B[39m):\n\u001B[0;32m---> 64\u001B[0m     trainable \u001B[38;5;241m=\u001B[39m \u001B[43mget_trainable_cls\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrainable\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     66\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(trainable, \u001B[38;5;28mtype\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m (\n\u001B[1;32m     67\u001B[0m     \u001B[38;5;28misinstance\u001B[39m(trainable, FunctionType)\n\u001B[1;32m     68\u001B[0m     \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(trainable, partial)\n\u001B[1;32m     69\u001B[0m     \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mcallable\u001B[39m(trainable)\n\u001B[1;32m     70\u001B[0m )\n",
      "File \u001B[0;32m~/mambaforge/envs/ray/lib/python3.10/site-packages/ray/tune/registry.py:45\u001B[0m, in \u001B[0;36mget_trainable_cls\u001B[0;34m(trainable_name)\u001B[0m\n\u001B[1;32m     43\u001B[0m \u001B[38;5;129m@DeveloperAPI\u001B[39m\n\u001B[1;32m     44\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_trainable_cls\u001B[39m(trainable_name):\n\u001B[0;32m---> 45\u001B[0m     \u001B[43mvalidate_trainable\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrainable_name\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     46\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _global_registry\u001B[38;5;241m.\u001B[39mget(TRAINABLE_CLASS, trainable_name)\n",
      "File \u001B[0;32m~/mambaforge/envs/ray/lib/python3.10/site-packages/ray/tune/registry.py:55\u001B[0m, in \u001B[0;36mvalidate_trainable\u001B[0;34m(trainable_name)\u001B[0m\n\u001B[1;32m     53\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mray\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mrllib\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _register_all\n\u001B[0;32m---> 55\u001B[0m \u001B[43m_register_all\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     56\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m _has_trainable(trainable_name):\n",
      "File \u001B[0;32m~/mambaforge/envs/ray/lib/python3.10/site-packages/ray/rllib/__init__.py:39\u001B[0m, in \u001B[0;36m_register_all\u001B[0;34m()\u001B[0m\n\u001B[1;32m     36\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m key, get_trainable_class_and_config \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mlist\u001B[39m(ALGORITHMS\u001B[38;5;241m.\u001B[39mitems()) \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mlist\u001B[39m(\n\u001B[1;32m     37\u001B[0m     CONTRIBUTED_ALGORITHMS\u001B[38;5;241m.\u001B[39mitems()\n\u001B[1;32m     38\u001B[0m ):\n\u001B[0;32m---> 39\u001B[0m     register_trainable(key, \u001B[43mget_trainable_class_and_config\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;241m0\u001B[39m])\n\u001B[1;32m     41\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m key \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__fake\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__sigmoid_fake_data\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__parameter_tuning\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n",
      "File \u001B[0;32m~/mambaforge/envs/ray/lib/python3.10/site-packages/ray/rllib/algorithms/registry.py:65\u001B[0m, in \u001B[0;36m_import_bandit_lints\u001B[0;34m()\u001B[0m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_import_bandit_lints\u001B[39m():\n\u001B[0;32m---> 65\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mray\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mrllib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01malgorithms\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbandit\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbandit\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m BanditLinTS\n\u001B[1;32m     67\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m BanditLinTS, BanditLinTS\u001B[38;5;241m.\u001B[39mget_default_config()\n",
      "File \u001B[0;32m~/mambaforge/envs/ray/lib/python3.10/site-packages/ray/rllib/algorithms/bandit/__init__.py:1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mray\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mrllib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01malgorithms\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbandit\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbandit\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m      2\u001B[0m     BanditLinTS,\n\u001B[1;32m      3\u001B[0m     BanditLinUCB,\n\u001B[1;32m      4\u001B[0m     BanditLinTSConfig,\n\u001B[1;32m      5\u001B[0m     BanditLinUCBConfig,\n\u001B[1;32m      6\u001B[0m )\n\u001B[1;32m      8\u001B[0m __all__ \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m      9\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBanditLinTS\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     10\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBanditLinUCB\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     11\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBanditLinTSConfig\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     12\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBanditLinUCBConfig\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     13\u001B[0m ]\n",
      "File \u001B[0;32m~/mambaforge/envs/ray/lib/python3.10/site-packages/ray/rllib/algorithms/bandit/bandit.py:6\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mray\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mrllib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01malgorithms\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01malgorithm_config\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m AlgorithmConfig\n\u001B[0;32m----> 6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mray\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mrllib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01malgorithms\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbandit\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbandit_tf_policy\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m BanditTFPolicy\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mray\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mrllib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01malgorithms\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbandit\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbandit_torch_policy\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m BanditTorchPolicy\n",
      "File \u001B[0;32m~/mambaforge/envs/ray/lib/python3.10/site-packages/ray/rllib/algorithms/bandit/bandit_tf_policy.py:8\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mray\u001B[39;00m\n\u001B[0;32m----> 8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mray\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mrllib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01malgorithms\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbandit\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbandit_tf_model\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m      9\u001B[0m     DiscreteLinearModelThompsonSampling,\n\u001B[1;32m     10\u001B[0m     DiscreteLinearModelUCB,\n\u001B[1;32m     11\u001B[0m     DiscreteLinearModel,\n\u001B[1;32m     12\u001B[0m     ParametricLinearModelThompsonSampling,\n\u001B[1;32m     13\u001B[0m     ParametricLinearModelUCB,\n\u001B[1;32m     14\u001B[0m )\n\u001B[1;32m     15\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mray\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mrllib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodels\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcatalog\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ModelCatalog\n",
      "File \u001B[0;32m~/mambaforge/envs/ray/lib/python3.10/site-packages/ray/rllib/algorithms/bandit/bandit_tf_model.py:2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mgym\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtensorflow_probability\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mtfp\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mray\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mrllib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodels\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodelv2\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ModelV2\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'tensorflow_probability'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mTuneError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[14], line 17\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;66;03m# ``Tuner.fit()`` allows setting a custom log directory (other than ``~/ray-results``)\u001B[39;00m\n\u001B[1;32m      8\u001B[0m tuner \u001B[38;5;241m=\u001B[39m ray\u001B[38;5;241m.\u001B[39mtune\u001B[38;5;241m.\u001B[39mTuner(\n\u001B[1;32m      9\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPPO\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     10\u001B[0m     param_space\u001B[38;5;241m=\u001B[39mconfig,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     14\u001B[0m     ),\n\u001B[1;32m     15\u001B[0m )\n\u001B[0;32m---> 17\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[43mtuner\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     19\u001B[0m \u001B[38;5;66;03m# Get the best result based on a particular metric.\u001B[39;00m\n\u001B[1;32m     20\u001B[0m best_result \u001B[38;5;241m=\u001B[39m results\u001B[38;5;241m.\u001B[39mget_best_result(metric\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mepisode_reward_mean\u001B[39m\u001B[38;5;124m\"\u001B[39m, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmax\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/mambaforge/envs/ray/lib/python3.10/site-packages/ray/tune/tuner.py:274\u001B[0m, in \u001B[0;36mTuner.fit\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    272\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_local_tuner\u001B[38;5;241m.\u001B[39mfit()\n\u001B[1;32m    273\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m--> 274\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m TuneError(\n\u001B[1;32m    275\u001B[0m             _TUNER_FAILED_MSG\u001B[38;5;241m.\u001B[39mformat(\n\u001B[1;32m    276\u001B[0m                 path\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_local_tuner\u001B[38;5;241m.\u001B[39mget_experiment_checkpoint_dir()\n\u001B[1;32m    277\u001B[0m             )\n\u001B[1;32m    278\u001B[0m         ) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n\u001B[1;32m    279\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    280\u001B[0m     experiment_checkpoint_dir \u001B[38;5;241m=\u001B[39m ray\u001B[38;5;241m.\u001B[39mget(\n\u001B[1;32m    281\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_remote_tuner\u001B[38;5;241m.\u001B[39mget_experiment_checkpoint_dir\u001B[38;5;241m.\u001B[39mremote()\n\u001B[1;32m    282\u001B[0m     )\n",
      "\u001B[0;31mTuneError\u001B[0m: The Ray Tune run failed. Please inspect the previous error messages for a cause. After fixing the issue, you can restart the run from scratch or continue this run. To continue this run, you can use `tuner = Tuner.restore(\"/home/furman/ray_results/PPO\")`."
     ]
    }
   ],
   "source": [
    "import ray\n",
    "from ray import air, tune\n",
    "ray.shutdown()\n",
    "ray.init()\n",
    "\n",
    "config = PPOConfig().training(lr=tune.grid_search([0.01, 0.001, 0.0001])).framework('torch')\n",
    "# ``Tuner.fit()`` allows setting a custom log directory (other than ``~/ray-results``)\n",
    "tuner = ray.tune.Tuner(\n",
    "    \"PPO\",\n",
    "    param_space=config,\n",
    "    run_config=air.RunConfig(\n",
    "        stop={\"episode_reward_mean\": 150},\n",
    "        checkpoint_config=air.CheckpointConfig(checkpoint_at_end=True),\n",
    "    ),\n",
    ")\n",
    "\n",
    "results = tuner.fit()\n",
    "\n",
    "# Get the best result based on a particular metric.\n",
    "best_result = results.get_best_result(metric=\"episode_reward_mean\", mode=\"max\")\n",
    "\n",
    "# Get the best checkpoint corresponding to the best result.\n",
    "best_checkpoint = best_result.checkpoint"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-15T02:47:29.833741261Z",
     "start_time": "2023-06-15T02:47:13.814837690Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "env = gym.make(\"CartPole-v1\", render_mode=\"human\")\n",
    "after_training = \"after_training.mp4\"\n",
    "after_video = VideoRecorder(env, after_training)\n",
    "reps = 0\n",
    "while reps < 5:\n",
    "    observation, info = env.reset()\n",
    "    while not terminated:\n",
    "        env.render()\n",
    "        after_video.capture_frame()\n",
    "        action = algo.compute_single_action(observation=observation, explore=0)\n",
    "        observation, reward, terminated, truncated, info = env.step(env.action_space.sample())\n",
    "    reps += 1\n",
    "    terminated = False\n",
    "after_video.close()\n",
    "env.close()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-15T02:16:57.461093881Z",
     "start_time": "2023-06-15T02:16:52.434086327Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "array([ 0.24730873,  0.62726694, -0.21656461, -0.978816  ], dtype=float32)"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observation"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-15T02:17:06.752587738Z",
     "start_time": "2023-06-15T02:17:06.724664215Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo.compute_single_action(observation=observation)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-15T02:17:18.741444251Z",
     "start_time": "2023-06-15T02:17:18.717313300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
